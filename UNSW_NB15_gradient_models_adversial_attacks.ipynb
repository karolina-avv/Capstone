{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f146cd89-d9d4-4f9f-852f-457d4110fbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0acd54-7549-4095-8933-d87e9735cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /Users/kvv2005/.local/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: xgboost in /Users/kvv2005/.local/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: adversarial-robustness-toolbox in /Users/kvv2005/.local/lib/python3.12/site-packages (1.18.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from adversarial-robustness-toolbox) (4.66.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /Users/kvv2005/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/kvv2005/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/kvv2005/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow scikit-learn xgboost adversarial-robustness-toolbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e78939-d3ea-444f-8148-580a81f6ee46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6216e408-ff98-4d09-864b-29d7adaa804b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unsw_nb15_path = '/Users/kvv2005/Desktop/UNSW_NB15_training-set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad776770-e282-43ae-927c-c97b05a95036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv(unsw_nb15_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73dcfba5-fcd6-4614-966b-ffc0f42d82df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSL-KDD Dataset:\n",
      "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
      "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
      "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
      "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
      "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
      "\n",
      "          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "0   90909.0902  ...                 1               2             0   \n",
      "1  125000.0003  ...                 1               2             0   \n",
      "2  200000.0051  ...                 1               3             0   \n",
      "3  166666.6608  ...                 1               3             0   \n",
      "4  100000.0025  ...                 1               3             0   \n",
      "\n",
      "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "0           0                 0           1           2                0   \n",
      "1           0                 0           1           2                0   \n",
      "2           0                 0           1           3                0   \n",
      "3           0                 0           2           3                0   \n",
      "4           0                 0           2           3                0   \n",
      "\n",
      "   attack_cat  label  \n",
      "0      Normal      0  \n",
      "1      Normal      0  \n",
      "2      Normal      0  \n",
      "3      Normal      0  \n",
      "4      Normal      0  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "print('NSL-KDD Dataset:')\n",
    "print(nsl_kdd_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b7bba1d-2be1-49cc-827a-7f10c62007a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (82332, 44), Target shape: (82332,)\n"
     ]
    }
   ],
   "source": [
    "# Identify the last column as the target label\n",
    "target_column = df.columns[-1]\n",
    "\n",
    "# Separate features (all columns except the last one) and target\n",
    "X = df.iloc[:, :-1]  # All rows, all columns except the last\n",
    "y = df.iloc[:, -1]   # All rows, only the last column\n",
    "\n",
    "print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3b7745-dac1-4a4d-a636-b61017954cab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "id                   0\n",
      "dur                  0\n",
      "proto                0\n",
      "service              0\n",
      "state                0\n",
      "spkts                0\n",
      "dpkts                0\n",
      "sbytes               0\n",
      "dbytes               0\n",
      "rate                 0\n",
      "sttl                 0\n",
      "dttl                 0\n",
      "sload                0\n",
      "dload                0\n",
      "sloss                0\n",
      "dloss                0\n",
      "sinpkt               0\n",
      "dinpkt               0\n",
      "sjit                 0\n",
      "djit                 0\n",
      "swin                 0\n",
      "stcpb                0\n",
      "dtcpb                0\n",
      "dwin                 0\n",
      "tcprtt               0\n",
      "synack               0\n",
      "ackdat               0\n",
      "smean                0\n",
      "dmean                0\n",
      "trans_depth          0\n",
      "response_body_len    0\n",
      "ct_srv_src           0\n",
      "ct_state_ttl         0\n",
      "ct_dst_ltm           0\n",
      "ct_src_dport_ltm     0\n",
      "ct_dst_sport_ltm     0\n",
      "ct_dst_src_ltm       0\n",
      "is_ftp_login         0\n",
      "ct_ftp_cmd           0\n",
      "ct_flw_http_mthd     0\n",
      "ct_src_ltm           0\n",
      "ct_srv_dst           0\n",
      "is_sm_ips_ports      0\n",
      "attack_cat           0\n",
      "label                0\n",
      "dtype: int64\n",
      "New dataset shape after dropping missing values: (82332, 45)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if needed)\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(f\"New dataset shape after dropping missing values: {df_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b789e1e9-a93d-4109-ab06-4ca5bb60b2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['proto', 'service', 'state', 'attack_cat'], dtype='object')\n",
      "   id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0   1  0.000011    117        0      4      2      0     496       0   \n",
      "1   2  0.000008    117        0      4      2      0    1762       0   \n",
      "2   3  0.000005    117        0      4      2      0    1068       0   \n",
      "3   4  0.000006    117        0      4      2      0     900       0   \n",
      "4   5  0.000010    117        0      4      2      0    2126       0   \n",
      "\n",
      "          rate  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
      "0   90909.0902  ...                 1                 1               2   \n",
      "1  125000.0003  ...                 1                 1               2   \n",
      "2  200000.0051  ...                 1                 1               3   \n",
      "3  166666.6608  ...                 2                 1               3   \n",
      "4  100000.0025  ...                 2                 1               3   \n",
      "\n",
      "   is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
      "0             0           0                 0           1           2   \n",
      "1             0           0                 0           1           2   \n",
      "2             0           0                 0           1           3   \n",
      "3             0           0                 0           2           3   \n",
      "4             0           0                 0           2           3   \n",
      "\n",
      "   is_sm_ips_ports  attack_cat  \n",
      "0                0           6  \n",
      "1                0           6  \n",
      "2                0           6  \n",
      "3                0           6  \n",
      "4                0           6  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "label_encoders = {}  # Store encoders to decode later if needed\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57ab84c8-281a-435a-aac8-680a6784fa7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features shape: (82332, 44)\n",
      "First 5 rows of scaled features:\n",
      " [[-1.73202977 -0.21372745  0.41056274 -0.6744059   0.93269533 -0.1244551\n",
      "  -0.15181641 -0.04368361 -0.08736871  0.05718096  0.71944006 -0.82039474\n",
      "   0.6439127  -0.26349797 -0.07353054 -0.11324391 -0.12217934 -0.09416902\n",
      "  -0.11217671 -0.14721836 -1.04791956 -0.77984004 -0.77675409 -1.00624379\n",
      "  -0.48202491 -0.41290971 -0.48407269  0.52031938 -0.47537059 -0.17364821\n",
      "  -0.04190986 -0.68047371  0.59102107 -0.56365986 -0.46831162 -0.45018649\n",
      "  -0.47799398 -0.09085748 -0.09061736 -0.20314282 -0.64003277 -0.64419018\n",
      "  -0.10607007  0.70710473]\n",
      " [-1.7319877  -0.21372808  0.41056274 -0.6744059   0.93269533 -0.1244551\n",
      "  -0.15181641 -0.03630776 -0.08736871  0.28656484  0.71944006 -0.82039474\n",
      "   4.53935073 -0.26349797 -0.07353054 -0.11324391 -0.12217982 -0.09416902\n",
      "  -0.11217671 -0.14721836 -1.04791956 -0.77984004 -0.77675409 -1.00624379\n",
      "  -0.48202491 -0.41290971 -0.48407269  3.55671589 -0.47537059 -0.17364821\n",
      "  -0.04190986 -0.68047371  0.59102107 -0.56365986 -0.46831162 -0.45018649\n",
      "  -0.47799398 -0.09085748 -0.09061736 -0.20314282 -0.64003277 -0.64419018\n",
      "  -0.10607007  0.70710473]\n",
      " [-1.73194562 -0.21372872  0.41056274 -0.6744059   0.93269533 -0.1244551\n",
      "  -0.15181641 -0.04035108 -0.08736871  0.79120941  0.71944006 -0.82039474\n",
      "   4.39145853 -0.26349797 -0.07353054 -0.11324391 -0.12218031 -0.09416902\n",
      "  -0.11217671 -0.14721836 -1.04791956 -0.77984004 -0.77675409 -1.00624379\n",
      "  -0.48202491 -0.41290971 -0.48407269  1.89221417 -0.47537059 -0.17364821\n",
      "  -0.04190986 -0.59030419  0.59102107 -0.56365986 -0.46831162 -0.45018649\n",
      "  -0.39039089 -0.09085748 -0.09061736 -0.20314282 -0.64003277 -0.554273\n",
      "  -0.10607007  0.70710473]\n",
      " [-1.73190355 -0.21372851  0.41056274 -0.6744059   0.93269533 -0.1244551\n",
      "  -0.15181641 -0.04132986 -0.08736871  0.56692287  0.71944006 -0.82039474\n",
      "   2.97703091 -0.26349797 -0.07353054 -0.11324391 -0.12218015 -0.09416902\n",
      "  -0.11217671 -0.14721836 -1.04791956 -0.77984004 -0.77675409 -1.00624379\n",
      "  -0.48202491 -0.41290971 -0.48407269  1.48928004 -0.47537059 -0.17364821\n",
      "  -0.04190986 -0.59030419  0.59102107 -0.44486766 -0.34911492 -0.45018649\n",
      "  -0.39039089 -0.09085748 -0.09061736 -0.20314282 -0.52298985 -0.554273\n",
      "  -0.10607007  0.70710473]\n",
      " [-1.73186147 -0.21372766  0.41056274 -0.6744059   0.93269533 -0.1244551\n",
      "  -0.15181641 -0.03418706 -0.08736871  0.11835001  0.71944006 -0.82039474\n",
      "   4.36921911 -0.26349797 -0.07353054 -0.11324391 -0.1221795  -0.09416902\n",
      "  -0.11217671 -0.14721836 -1.04791956 -0.77984004 -0.77675409 -1.00624379\n",
      "  -0.48202491 -0.41290971 -0.48407269  4.42973984 -0.47537059 -0.17364821\n",
      "  -0.04190986 -0.59030419  0.59102107 -0.44486766 -0.34911492 -0.45018649\n",
      "  -0.39039089 -0.09085748 -0.09061736 -0.20314282 -0.52298985 -0.554273\n",
      "  -0.10607007  0.70710473]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Scaled features shape: {X_scaled.shape}\")\n",
    "print('First 5 rows of scaled features:\\n', X_scaled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83936d5b-2818-48af-ac70-df0cbe997601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/bin/python'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02277293-24a9-4396-9bfe-76e7c2603fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  absl-py            conda-forge/noarch::absl-py-2.1.0-pyhd8ed1ab_0 \n",
      "  keras              conda-forge/noarch::keras-3.6.0-pyhd8ed1ab_0 \n",
      "  libexpat           conda-forge/osx-64::libexpat-2.6.2-h73e2aa4_0 \n",
      "  libsqlite          conda-forge/osx-64::libsqlite-3.46.0-h1b8f9f3_0 \n",
      "  libzlib            conda-forge/osx-64::libzlib-1.2.13-h87427d6_6 \n",
      "  ml_dtypes          pkgs/main/osx-64::ml_dtypes-0.4.0-py312h77d3abe_0 \n",
      "  namex              conda-forge/noarch::namex-0.0.8-pyhd8ed1ab_0 \n",
      "  optree             pkgs/main/osx-64::optree-0.12.1-py312h1962661_0 \n",
      "  python_abi         conda-forge/osx-64::python_abi-3.12-5_cp312 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2024.3.11-~ --> conda-forge::ca-certificates-2024.8.30-h8857fd0_0 \n",
      "  certifi            pkgs/main/osx-64::certifi-2024.6.2-py~ --> conda-forge/noarch::certifi-2024.8.30-pyhd8ed1ab_0 \n",
      "  conda              pkgs/main::conda-24.5.0-py312hecd8cb5~ --> conda-forge::conda-24.9.2-py312hb401068_0 \n",
      "  openssl              pkgs/main::openssl-3.0.14-h46256e1_0 --> conda-forge::openssl-3.3.2-hd23fc13_0 \n",
      "  zlib                    pkgs/main::zlib-1.2.13-h4b97444_1 --> conda-forge::zlib-1.2.13-h87427d6_6 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  python                pkgs/main::python-3.12.4-hcd54a6c_1 --> conda-forge::python-3.12.2-h9f0c242_0_cpython \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /opt/anaconda3\n",
      "  uid: 355216707\n",
      "  gid: 579533871\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab9caf29-7764-4ade-b14f-5e572d699d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvv2005/.local/lib/python3.12/site-packages/art/estimators/certification/__init__.py:30: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier, SklearnClassifier, XGBoostClassifier\n",
    "from art.attacks.evasion import HopSkipJump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33a38774-7e7e-4f75-870e-ae624fdc1682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (65865, 44), Test Set: (16467, 44)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Set: {X_train.shape}, Test Set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aedbdb1d-c373-4138-9301-556f7de8f457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - accuracy: 0.9647 - loss: 0.0926 - val_accuracy: 0.9995 - val_loss: 0.0144\n",
      "Epoch 2/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9997 - val_loss: 0.0130\n",
      "Epoch 3/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 1.0000 - loss: 2.7006e-04 - val_accuracy: 0.9997 - val_loss: 0.0125\n",
      "Epoch 4/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9995 - val_loss: 0.0394\n",
      "Epoch 5/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.9997 - loss: 0.0032 - val_accuracy: 0.9995 - val_loss: 0.0322\n",
      "Epoch 6/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9997 - val_loss: 0.0278\n",
      "Epoch 7/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 1.0000 - loss: 1.3581e-05 - val_accuracy: 0.9997 - val_loss: 0.0341\n",
      "Epoch 8/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 1.0000 - loss: 4.0027e-06 - val_accuracy: 0.9997 - val_loss: 0.0388\n",
      "Epoch 9/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 1.0000 - loss: 1.8105e-06 - val_accuracy: 0.9997 - val_loss: 0.0422\n",
      "Epoch 10/10\n",
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 1.0000 - loss: 7.8816e-07 - val_accuracy: 0.9997 - val_loss: 0.0440\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step\n",
      "Model Accuracy on Clean Test Data: 1.0\n",
      "Classification Report on Clean Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7418\n",
      "           1       1.00      1.00      1.00      9049\n",
      "\n",
      "    accuracy                           1.00     16467\n",
      "   macro avg       1.00      1.00      1.00     16467\n",
      "weighted avg       1.00      1.00      1.00     16467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a simple neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on clean data\n",
    "y_pred_clean = model.predict(X_test).argmax(axis=1)\n",
    "accuracy_clean = accuracy_score(y_test, y_pred_clean)\n",
    "\n",
    "print(f\"Model Accuracy on Clean Test Data: {accuracy_clean}\")\n",
    "print(\"Classification Report on Clean Test Data:\")\n",
    "print(classification_report(y_test, y_pred_clean, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07c15821-a4d7-4561-ab80-fdc594961787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the TensorFlow model with ART's TensorFlowV2Classifier\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    nb_classes=len(set(y)),\n",
    "    input_shape=(X_train.shape[1],),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e357170e-45c9-4b7b-af73-8770a325f9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Model Accuracy on FGSM Adversarial Examples: 1.0\n",
      "Classification Report on FGSM Adversarial Examples:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "# Initialize the FGSM attack\n",
    "fgsm = FastGradientMethod(estimator=classifier, eps=0.1)\n",
    "\n",
    "# Generate adversarial examples\n",
    "X_test_adv_fgsm = fgsm.generate(x=X_test[:10])\n",
    "\n",
    "# Predict on the adversarial examples\n",
    "y_pred_fgsm = model.predict(X_test_adv_fgsm).argmax(axis=1)\n",
    "\n",
    "# Evaluate performance on adversarial examples\n",
    "accuracy_fgsm = accuracy_score(y_test[:10], y_pred_fgsm)\n",
    "print(f\"Model Accuracy on FGSM Adversarial Examples: {accuracy_fgsm}\")\n",
    "print(\"Classification Report on FGSM Adversarial Examples:\")\n",
    "print(classification_report(y_test[:10], y_pred_fgsm, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd1d0b58-1fee-41a0-8dca-5ee46536c438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f4eb452adf4ef497ce89be433e32c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Model Accuracy on PGD Adversarial Examples: 1.0\n",
      "Classification Report on PGD Adversarial Examples:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 16:27:31.982469: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "# Initialize the PGD attack\n",
    "pgd = ProjectedGradientDescent(estimator=classifier, eps=0.1, eps_step=0.01, max_iter=50)\n",
    "\n",
    "# Generate adversarial examples using PGD\n",
    "X_test_adv_pgd = pgd.generate(x=X_test[:10])\n",
    "\n",
    "# Predict on the adversarial examples\n",
    "y_pred_pgd = model.predict(X_test_adv_pgd).argmax(axis=1)\n",
    "\n",
    "# Evaluate performance on PGD adversarial examples\n",
    "accuracy_pgd = accuracy_score(y_test[:10], y_pred_pgd)\n",
    "print(f\"Model Accuracy on PGD Adversarial Examples: {accuracy_pgd}\")\n",
    "print(\"Classification Report on PGD Adversarial Examples:\")\n",
    "print(classification_report(y_test[:10], y_pred_pgd, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11136ac2-1b86-41f5-8986-b591cdb2cb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aba5d539c5b4b5e851650982d07607b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Model Accuracy on C&W Adversarial Examples: 1.0\n",
      "Classification Report on C&W Adversarial Examples:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the C&W attack (L2 norm)\n",
    "from art.attacks.evasion import CarliniL2Method\n",
    "\n",
    "cw = CarliniL2Method(classifier=classifier, targeted=False, max_iter=10)\n",
    "\n",
    "# Generate adversarial examples using C&W\n",
    "X_test_adv_cw = cw.generate(x=X_test[:10])\n",
    "\n",
    "# Predict on the adversarial examples\n",
    "y_pred_cw = model.predict(X_test_adv_cw).argmax(axis=1)\n",
    "\n",
    "# Evaluate performance on C&W adversarial examples\n",
    "accuracy_cw = accuracy_score(y_test[:10], y_pred_cw)\n",
    "print(f\"Model Accuracy on C&W Adversarial Examples: {accuracy_cw}\")\n",
    "print(\"Classification Report on C&W Adversarial Examples:\")\n",
    "print(classification_report(y_test[:10], y_pred_cw, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "476e5849-f9d9-4137-8f08-9ff53ee6a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import ART classifiers and attacks\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent, CarliniL2Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58cc82b7-cfa2-4151-a23b-a81c68af551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (100777, 122), Test Set: (25195, 122)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_scaled (features) and y_encoded (labels) are ready\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Set: {X_train.shape}, Test Set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63955475-45e2-435a-95e2-77827322b9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvv2005/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 691us/step - accuracy: 0.9536 - loss: 0.2241 - val_accuracy: 0.9907 - val_loss: 0.0301\n",
      "Epoch 2/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 644us/step - accuracy: 0.9902 - loss: 0.0320 - val_accuracy: 0.9948 - val_loss: 0.0203\n",
      "Epoch 3/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 691us/step - accuracy: 0.9916 - loss: 0.0248 - val_accuracy: 0.9920 - val_loss: 0.0223\n",
      "Epoch 4/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - accuracy: 0.9930 - loss: 0.0221 - val_accuracy: 0.9942 - val_loss: 0.0220\n",
      "Epoch 5/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - accuracy: 0.9933 - loss: 0.0205 - val_accuracy: 0.9946 - val_loss: 0.0204\n",
      "Epoch 6/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665us/step - accuracy: 0.9941 - loss: 0.0190 - val_accuracy: 0.9944 - val_loss: 0.0208\n",
      "Epoch 7/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - accuracy: 0.9941 - loss: 0.0177 - val_accuracy: 0.9934 - val_loss: 0.0210\n",
      "Epoch 8/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - accuracy: 0.9942 - loss: 0.0167 - val_accuracy: 0.9960 - val_loss: 0.0163\n",
      "Epoch 9/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - accuracy: 0.9945 - loss: 0.0172 - val_accuracy: 0.9951 - val_loss: 0.0193\n",
      "Epoch 10/10\n",
      "\u001b[1m2835/2835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - accuracy: 0.9951 - loss: 0.0147 - val_accuracy: 0.9951 - val_loss: 0.0184\n"
     ]
    }
   ],
   "source": [
    "# Define MLP Model\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(set(y_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "mlp_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Wrap the model with ART’s TensorFlowV2Classifier\n",
    "mlp_classifier = TensorFlowV2Classifier(\n",
    "    model=mlp_model,\n",
    "    nb_classes=len(set(y_encoded)),\n",
    "    input_shape=(X_train.shape[1],),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85ec3ed3-1a7c-4b64-b200-4612b5db04ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step\n",
      "Classification Report (MLP - FGSM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.11      0.02       201\n",
      "           1       1.00      0.29      0.44         7\n",
      "           3       1.00      0.79      0.88        14\n",
      "           4       0.67      1.00      0.80         2\n",
      "           5       0.87      0.65      0.74       743\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       1.00      0.00      0.00         1\n",
      "           9       0.99      0.99      0.99      8238\n",
      "          10       0.55      0.79      0.65       298\n",
      "          11       0.95      0.78      0.86     13386\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       0.95      0.58      0.72        36\n",
      "          15       0.87      0.94      0.90       583\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.85      0.89      0.87       749\n",
      "          18       0.94      0.94      0.94       551\n",
      "          19       1.00      0.00      0.00         1\n",
      "          20       0.94      1.00      0.97       196\n",
      "          21       0.08      0.25      0.12       176\n",
      "          22       0.25      0.75      0.38         4\n",
      "\n",
      "    accuracy                           0.85     25195\n",
      "   macro avg       0.71      0.63      0.60     25195\n",
      "weighted avg       0.94      0.85      0.89     25195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FGSM Attack\n",
    "fgsm = FastGradientMethod(estimator=mlp_classifier, eps=0.1)\n",
    "X_test_adv_fgsm = fgsm.generate(x=X_test)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_fgsm = mlp_model.predict(X_test_adv_fgsm).argmax(axis=1)\n",
    "print(\"Classification Report (MLP - FGSM):\")\n",
    "print(classification_report(y_test, y_pred_fgsm, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4351af51-c612-4ce5-97c8-c537ebbd2529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e157365a99402d983eb661ec18b8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 14:39:37.757961: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step\n",
      "Classification Report (MLP - PGD):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.06      0.01       201\n",
      "           1       1.00      0.14      0.25         7\n",
      "           2       0.00      1.00      0.00         0\n",
      "           3       0.92      0.79      0.85        14\n",
      "           4       0.67      1.00      0.80         2\n",
      "           5       0.74      0.36      0.48       743\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       1.00      0.00      0.00         1\n",
      "           9       0.99      0.99      0.99      8238\n",
      "          10       0.37      0.78      0.50       298\n",
      "          11       0.94      0.71      0.81     13386\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       0.77      0.47      0.59        36\n",
      "          15       0.82      0.93      0.87       583\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.74      0.84      0.78       749\n",
      "          18       0.89      0.93      0.91       551\n",
      "          19       1.00      0.00      0.00         1\n",
      "          20       0.87      0.99      0.93       196\n",
      "          21       0.06      0.21      0.09       176\n",
      "          22       0.11      0.75      0.19         4\n",
      "\n",
      "    accuracy                           0.80     25195\n",
      "   macro avg       0.63      0.61      0.51     25195\n",
      "weighted avg       0.92      0.80      0.85     25195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PGD Attack\n",
    "pgd = ProjectedGradientDescent(estimator=mlp_classifier, eps=0.1, eps_step=0.01, max_iter=50)\n",
    "X_test_adv_pgd = pgd.generate(x=X_test)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_pgd = mlp_model.predict(X_test_adv_pgd).argmax(axis=1)\n",
    "print(\"Classification Report (MLP - PGD):\")\n",
    "print(classification_report(y_test, y_pred_pgd, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d795e-252c-4735-8cc9-5ff3ace62436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7d5b2d519e402f831c5d6a5d93eeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/25195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C&W Attack\n",
    "cw = CarliniL2Method(classifier=mlp_classifier, targeted=False, max_iter=1)\n",
    "X_test_adv_cw = cw.generate(x=X_test)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_cw = mlp_model.predict(X_test_adv_cw).argmax(axis=1)\n",
    "print(\"Classification Report (MLP - C&W):\")\n",
    "print(classification_report(y_test, y_pred_cw, zero_division=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6879425-45e9-440b-b6ab-2280499d7fca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Conv1D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m X_test_cnn \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define CNN Model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m----> 7\u001b[0m     Conv1D(\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m      8\u001b[0m     MaxPooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      9\u001b[0m     Flatten(),\n\u001b[1;32m     10\u001b[0m     Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     11\u001b[0m     Dense(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(y_encoded)), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m ])\n\u001b[1;32m     14\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mfit(X_train_cnn, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Conv1D' is not defined"
     ]
    }
   ],
   "source": [
    "# Reshape input for CNN\n",
    "X_train_cnn = X_train[..., None]\n",
    "X_test_cnn = X_test[..., None]\n",
    "\n",
    "# Define CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(set(y_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Wrap the model with ART’s TensorFlowV2Classifier\n",
    "cnn_classifier = TensorFlowV2Classifier(\n",
    "    model=cnn_model,\n",
    "    nb_classes=len(set(y_encoded)),\n",
    "    input_shape=(X_train.shape[1], 1),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "93044828-3929-4278-bdbc-12cdd9fc7b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step\n",
      "Classification Report (CNN - FGSM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.19      0.05       201\n",
      "           1       0.67      0.29      0.40         7\n",
      "           2       0.00      1.00      0.00         0\n",
      "           3       1.00      0.86      0.92        14\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.85      0.53      0.66       743\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.99      0.99      0.99      8238\n",
      "          10       0.45      0.81      0.58       298\n",
      "          11       0.95      0.79      0.86     13386\n",
      "          12       1.00      0.00      0.00         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      0.97      0.99        36\n",
      "          15       0.85      0.96      0.90       583\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.58      0.91      0.71       749\n",
      "          18       0.94      0.95      0.95       551\n",
      "          19       1.00      0.00      0.00         1\n",
      "          20       1.00      1.00      1.00       196\n",
      "          21       0.10      0.42      0.16       176\n",
      "          22       0.17      0.25      0.20         4\n",
      "\n",
      "    accuracy                           0.86     25195\n",
      "   macro avg       0.66      0.61      0.53     25195\n",
      "weighted avg       0.93      0.86      0.88     25195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FGSM Attack\n",
    "fgsm = FastGradientMethod(estimator=cnn_classifier, eps=0.1)\n",
    "X_test_adv_fgsm_cnn = fgsm.generate(x=X_test_cnn)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_fgsm_cnn = cnn_model.predict(X_test_adv_fgsm_cnn).argmax(axis=1)\n",
    "print(\"Classification Report (CNN - FGSM):\")\n",
    "print(classification_report(y_test, y_pred_fgsm_cnn, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b4eded71-c292-4415-ad6d-d561c06993de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 18:05:59.474574: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step\n",
      "Classification Report (CNN - PGD):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.11      0.02       201\n",
      "           1       0.67      0.29      0.40         7\n",
      "           3       1.00      0.86      0.92        14\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.71      0.31      0.43       743\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       1.00      0.00      0.00         1\n",
      "           9       0.99      0.99      0.99      8238\n",
      "          10       0.36      0.69      0.47       298\n",
      "          11       0.92      0.67      0.77     13386\n",
      "          12       1.00      0.00      0.00         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      0.94      0.97        36\n",
      "          15       0.81      0.95      0.87       583\n",
      "          16       1.00      0.00      0.00         2\n",
      "          17       0.50      0.88      0.64       749\n",
      "          18       0.90      0.95      0.92       551\n",
      "          19       1.00      0.00      0.00         1\n",
      "          20       1.00      0.99      1.00       196\n",
      "          21       0.05      0.26      0.09       176\n",
      "          22       0.05      0.25      0.09         4\n",
      "\n",
      "    accuracy                           0.78     25195\n",
      "   macro avg       0.71      0.55      0.52     25195\n",
      "weighted avg       0.90      0.78      0.82     25195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PGD Attack\n",
    "pgd = ProjectedGradientDescent(estimator=cnn_classifier, eps=0.1, eps_step=0.01, max_iter=50)\n",
    "X_test_adv_pgd_cnn = pgd.generate(x=X_test_cnn)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_pgd_cnn = cnn_model.predict(X_test_adv_pgd_cnn).argmax(axis=1)\n",
    "print(\"Classification Report (CNN - PGD):\")\n",
    "print(classification_report(y_test, y_pred_pgd_cnn, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fd3be93-fadc-4dfb-bbff-f5dd70c13525",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# C&W Attack\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cw \u001b[38;5;241m=\u001b[39m CarliniL2Method(classifier\u001b[38;5;241m=\u001b[39mcnn_classifier, targeted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m X_test_adv_cw_cnn \u001b[38;5;241m=\u001b[39m cw\u001b[38;5;241m.\u001b[39mgenerate(x\u001b[38;5;241m=\u001b[39mX_test_cnn)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Predictions and Evaluation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# C&W Attack\n",
    "cw = CarliniL2Method(classifier=cnn_classifier, targeted=False, max_iter=10)\n",
    "X_test_adv_cw_cnn = cw.generate(x=X_test_cnn)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_cw_cnn = cnn_model.predict(X_test_adv_cw_cnn).argmax(axis=1)\n",
    "print(\"Classification Report (CNN - C&W):\")\n",
    "print(classification_report(y_test, y_pred_cw_cnn, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1607f7-9277-4250-968b-472bfea7165e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
