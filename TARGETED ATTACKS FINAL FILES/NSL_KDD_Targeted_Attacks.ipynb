{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915c09e8-8287-4a37-9bdc-18a5467ea852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad776770-e282-43ae-927c-c97b05a95036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/marlenawasiak/Desktop/Data_Collection/NSL_KDD_Train.csv')\n",
    "test_data = pd.read_csv('/Users/marlenawasiak/Desktop/Data_Collection/NSL_KDD_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1607f7-9277-4250-968b-472bfea7165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:, :-1]\n",
    "y_train = train_data.iloc[:, -1]\n",
    "X_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]\n",
    "\n",
    "common_columns = X_train.columns.intersection(X_test.columns)\n",
    "X_train = X_train[common_columns]\n",
    "X_test = X_test[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e766c-3bec-48df-a3ed-4eb7991fd3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label classes: ['apache2' 'back' 'buffer_overflow' 'ftp_write' 'guess_passwd'\n",
      " 'httptunnel' 'imap' 'ipsweep' 'land' 'loadmodule' 'mailbomb' 'mscan'\n",
      " 'multihop' 'named' 'neptune' 'nmap' 'normal' 'perl' 'phf' 'pod'\n",
      " 'portsweep' 'processtable' 'ps' 'rootkit' 'saint' 'satan' 'sendmail'\n",
      " 'smurf' 'snmpgetattack' 'snmpguess' 'spy' 'sqlattack' 'teardrop'\n",
      " 'udpstorm' 'warezclient' 'warezmaster' 'worm' 'xlock' 'xsnoop' 'xterm']\n",
      "Original training data shape: (125972, 28), (125972,)\n",
      "Resampled training data shape: (1548866, 28), (1548866,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 502us/step - accuracy: 0.9488 - loss: 0.1647 - val_accuracy: 0.2907 - val_loss: 12.3759\n",
      "Epoch 2/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 457us/step - accuracy: 0.9814 - loss: 0.0574 - val_accuracy: 0.2906 - val_loss: 17.4702\n",
      "Epoch 3/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 453us/step - accuracy: 0.9840 - loss: 0.0493 - val_accuracy: 0.0920 - val_loss: 20.5927\n",
      "Epoch 4/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 454us/step - accuracy: 0.9851 - loss: 0.0463 - val_accuracy: 0.1941 - val_loss: 25.0936\n",
      "Epoch 5/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 455us/step - accuracy: 0.9860 - loss: 0.0434 - val_accuracy: 0.1413 - val_loss: 27.3747\n",
      "Epoch 6/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 457us/step - accuracy: 0.9859 - loss: 0.0435 - val_accuracy: 0.2487 - val_loss: 32.6592\n",
      "Epoch 7/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 497us/step - accuracy: 0.9865 - loss: 0.0419 - val_accuracy: 0.3689 - val_loss: 40.3727\n",
      "Epoch 8/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 474us/step - accuracy: 0.9868 - loss: 0.0417 - val_accuracy: 0.3708 - val_loss: 47.8618\n",
      "Epoch 9/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 470us/step - accuracy: 0.9872 - loss: 0.0400 - val_accuracy: 0.2321 - val_loss: 43.9183\n",
      "Epoch 10/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 469us/step - accuracy: 0.9871 - loss: 0.0402 - val_accuracy: 0.2990 - val_loss: 50.3843\n",
      "Epoch 11/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 474us/step - accuracy: 0.9874 - loss: 0.0397 - val_accuracy: 0.2934 - val_loss: 51.2127\n",
      "Epoch 12/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 478us/step - accuracy: 0.9876 - loss: 0.0393 - val_accuracy: 0.2061 - val_loss: 54.2434\n",
      "Epoch 13/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 471us/step - accuracy: 0.9876 - loss: 0.0394 - val_accuracy: 0.3469 - val_loss: 73.9682\n",
      "Epoch 14/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 475us/step - accuracy: 0.9878 - loss: 0.0389 - val_accuracy: 0.3344 - val_loss: 81.3544\n",
      "Epoch 15/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 475us/step - accuracy: 0.9878 - loss: 0.0392 - val_accuracy: 0.3648 - val_loss: 87.9550\n",
      "Epoch 16/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 480us/step - accuracy: 0.9879 - loss: 0.0386 - val_accuracy: 0.2855 - val_loss: 87.5144\n",
      "Epoch 17/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 476us/step - accuracy: 0.9882 - loss: 0.0383 - val_accuracy: 0.2212 - val_loss: 79.9025\n",
      "Epoch 18/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 480us/step - accuracy: 0.9883 - loss: 0.0375 - val_accuracy: 0.1097 - val_loss: 87.2168\n",
      "Epoch 19/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 479us/step - accuracy: 0.9880 - loss: 0.0386 - val_accuracy: 0.1448 - val_loss: 108.1821\n",
      "Epoch 20/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 480us/step - accuracy: 0.9883 - loss: 0.0379 - val_accuracy: 0.1217 - val_loss: 99.6911\n",
      "Epoch 21/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 480us/step - accuracy: 0.9883 - loss: 0.0378 - val_accuracy: 0.2282 - val_loss: 116.2139\n",
      "Epoch 22/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 480us/step - accuracy: 0.9884 - loss: 0.0374 - val_accuracy: 0.1939 - val_loss: 120.7808\n",
      "Epoch 23/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 481us/step - accuracy: 0.9884 - loss: 0.0378 - val_accuracy: 0.1992 - val_loss: 141.1953\n",
      "Epoch 24/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 478us/step - accuracy: 0.9885 - loss: 0.0383 - val_accuracy: 0.3832 - val_loss: 164.2418\n",
      "Epoch 25/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 482us/step - accuracy: 0.9885 - loss: 0.0382 - val_accuracy: 0.1919 - val_loss: 146.2442\n",
      "Epoch 26/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 480us/step - accuracy: 0.9884 - loss: 0.0382 - val_accuracy: 0.2957 - val_loss: 154.9455\n",
      "Epoch 27/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 483us/step - accuracy: 0.9885 - loss: 0.0381 - val_accuracy: 0.4426 - val_loss: 180.3195\n",
      "Epoch 28/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485us/step - accuracy: 0.9883 - loss: 0.0387 - val_accuracy: 0.2654 - val_loss: 178.7477\n",
      "Epoch 29/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 483us/step - accuracy: 0.9885 - loss: 0.0380 - val_accuracy: 0.2655 - val_loss: 227.6991\n",
      "Epoch 30/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 488us/step - accuracy: 0.9886 - loss: 0.0385 - val_accuracy: 0.2567 - val_loss: 210.9292\n",
      "Epoch 31/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 484us/step - accuracy: 0.9889 - loss: 0.0369 - val_accuracy: 0.2694 - val_loss: 226.8568\n",
      "Epoch 32/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 486us/step - accuracy: 0.9886 - loss: 0.0390 - val_accuracy: 0.3340 - val_loss: 228.4021\n",
      "Epoch 33/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 486us/step - accuracy: 0.9886 - loss: 0.0383 - val_accuracy: 0.3030 - val_loss: 222.1998\n",
      "Epoch 34/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 488us/step - accuracy: 0.9884 - loss: 0.0379 - val_accuracy: 0.4424 - val_loss: 319.8352\n",
      "Epoch 35/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485us/step - accuracy: 0.9889 - loss: 0.0370 - val_accuracy: 0.4309 - val_loss: 273.3315\n",
      "Epoch 36/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 489us/step - accuracy: 0.9885 - loss: 0.0394 - val_accuracy: 0.4606 - val_loss: 322.2614\n",
      "Epoch 37/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 490us/step - accuracy: 0.9889 - loss: 0.0372 - val_accuracy: 0.4527 - val_loss: 325.7599\n",
      "Epoch 38/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 486us/step - accuracy: 0.9886 - loss: 0.0379 - val_accuracy: 0.4096 - val_loss: 265.0580\n",
      "Epoch 39/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 490us/step - accuracy: 0.9888 - loss: 0.0380 - val_accuracy: 0.4413 - val_loss: 251.2333\n",
      "Epoch 40/40\n",
      "\u001b[1m24202/24202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485us/step - accuracy: 0.9888 - loss: 0.0375 - val_accuracy: 0.3986 - val_loss: 286.1449\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "Test Accuracy: 0.3986159783524819\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        apache2       1.00      0.00      0.00       737\n",
      "           back       0.00      0.00      0.00       359\n",
      "buffer_overflow       1.00      0.00      0.00        20\n",
      "      ftp_write       1.00      0.00      0.00         3\n",
      "   guess_passwd       1.00      0.00      0.00      1231\n",
      "     httptunnel       1.00      0.00      0.00       133\n",
      "           imap       0.00      0.00      0.00         1\n",
      "        ipsweep       0.00      0.01      0.00       141\n",
      "           land       1.00      0.00      0.00         7\n",
      "     loadmodule       1.00      0.00      0.00         2\n",
      "       mailbomb       1.00      0.00      0.00       293\n",
      "          mscan       1.00      0.00      0.00       996\n",
      "       multihop       0.00      0.00      0.00        18\n",
      "          named       1.00      0.00      0.00        17\n",
      "        neptune       0.58      0.31      0.40      4656\n",
      "           nmap       1.00      0.00      0.00        73\n",
      "         normal       0.64      0.76      0.70      9711\n",
      "           perl       1.00      0.00      0.00         2\n",
      "            phf       1.00      0.00      0.00         2\n",
      "            pod       0.00      0.00      0.00        41\n",
      "      portsweep       0.03      0.94      0.05       157\n",
      "   processtable       1.00      0.00      0.00       685\n",
      "             ps       1.00      0.00      0.00        15\n",
      "        rootkit       0.00      0.00      0.00        13\n",
      "          saint       1.00      0.00      0.00       319\n",
      "          satan       0.00      0.00      0.00       735\n",
      "       sendmail       1.00      0.00      0.00        14\n",
      "          smurf       0.00      0.00      0.00       665\n",
      "  snmpgetattack       1.00      0.00      0.00       178\n",
      "      snmpguess       1.00      0.00      0.00       331\n",
      "            spy       1.00      1.00      1.00         0\n",
      "      sqlattack       1.00      0.00      0.00         2\n",
      "       teardrop       1.00      0.00      0.00        12\n",
      "       udpstorm       1.00      0.00      0.00         2\n",
      "    warezclient       1.00      1.00      1.00         0\n",
      "    warezmaster       1.00      0.00      0.00       944\n",
      "           worm       1.00      0.00      0.00         2\n",
      "          xlock       1.00      0.00      0.00         9\n",
      "         xsnoop       1.00      0.00      0.00         4\n",
      "          xterm       1.00      0.00      0.00        13\n",
      "\n",
      "      micro avg       0.40      0.40      0.40     22543\n",
      "      macro avg       0.76      0.10      0.08     22543\n",
      "   weighted avg       0.67      0.40      0.38     22543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Step 1: Encode Categorical Features\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    combined_categories = pd.concat([X_train[col], X_test[col]], axis=0).astype(\"category\").cat.categories\n",
    "    X_train[col] = pd.Categorical(X_train[col], categories=combined_categories)\n",
    "    X_test[col] = pd.Categorical(X_test[col], categories=combined_categories)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))\n",
    "\n",
    "clip_thresholds = {\n",
    "    \"0.1\": X_train[\"0.1\"].quantile(0.99),\n",
    "    \"0.2\": X_train[\"0.2\"].quantile(0.99)\n",
    "}\n",
    "\n",
    "X_train_clipped = X_train.copy()\n",
    "X_test_clipped = X_test.copy()\n",
    "\n",
    "for col, threshold in clip_thresholds.items():\n",
    "    X_train_clipped[col] = X_train[col].clip(upper=threshold)\n",
    "    X_test_clipped[col] = X_test[col].clip(upper=threshold)\n",
    "\n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "X_train_scaled = scaler.fit_transform(X_train_clipped)\n",
    "X_test_scaled = scaler.transform(X_test_clipped)\n",
    "X_train_scaled = np.clip(X_train_scaled, -3, 3)\n",
    "X_test_scaled = np.clip(X_test_scaled, -3, 3)\n",
    "all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Label classes:\", label_encoder.classes_)\n",
    "\n",
    "class_counts = Counter(y_train_encoded)\n",
    "min_class_size = min(class_counts.values())\n",
    "smote = SMOTE(random_state=42, k_neighbors=min(min_class_size - 1, 5))\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train_encoded)\n",
    "\n",
    "print(f\"Original training data shape: {X_train_scaled.shape}, {y_train_encoded.shape}\")\n",
    "print(f\"Resampled training data shape: {X_train_resampled.shape}, {y_train_resampled.shape}\")\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_resampled.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train_resampled, y_train_resampled, \n",
    "    epochs=40, batch_size=64, \n",
    "    validation_data=(X_test_scaled, y_test_encoded), \n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred_encoded = model.predict(X_test_scaled).argmax(axis=1)\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "class_report = classification_report(\n",
    "    y_test_encoded, \n",
    "    y_pred_encoded, \n",
    "    labels=range(len(label_encoder.classes_)), \n",
    "    target_names=label_encoder.classes_, \n",
    "    zero_division=1\n",
    ")\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e8b4b-1fca-4dcf-a1c4-f33e0578a7da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent, CarliniL2Method\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "import tensorflow as tf\n",
    "\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    nb_classes=len(label_encoder.classes_),\n",
    "    input_shape=(X_train_scaled.shape[1],),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n",
    "\n",
    "critical_features = [19, 23, 2, 26, 20] \n",
    "static_mask = np.zeros_like(X_test_scaled)\n",
    "static_mask[:, critical_features] = 1  \n",
    "def apply_static_mask(X_original, X_adv, mask):\n",
    "    \"\"\"\n",
    "    Applies a static mask to perturb only selected features.\n",
    "    Args:\n",
    "        X_original: The original input data.\n",
    "        X_adv: The adversarial examples.\n",
    "        mask: A mask indicating which features to perturb (1 = perturb, 0 = keep original).\n",
    "    Returns:\n",
    "        Masked adversarial examples.\n",
    "    \"\"\"\n",
    "    return X_original + (X_adv - X_original) * mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cd0b3-9866-4d98-8411-0010144727ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FGSM Attack with Static Mask ---\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step\n",
      "FGSM Adversarial Accuracy (eps=4.0): 0.35106241405314287\n",
      "FGSM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       737\n",
      "           1       0.00      0.00      0.00       359\n",
      "           2       1.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00      1231\n",
      "           5       1.00      0.00      0.00       133\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00       141\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       1.00      0.00      0.00         2\n",
      "          10       1.00      0.00      0.00       293\n",
      "          11       1.00      0.00      0.00       996\n",
      "          12       0.00      0.00      0.00        18\n",
      "          13       1.00      0.00      0.00        17\n",
      "          14       0.39      0.33      0.35      4656\n",
      "          15       0.00      0.00      0.00        73\n",
      "          16       0.42      0.66      0.51      9711\n",
      "          17       1.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       1.00      0.00      0.00        41\n",
      "          20       0.00      0.00      0.00       157\n",
      "          21       1.00      0.00      0.00       685\n",
      "          22       1.00      0.00      0.00        15\n",
      "          23       0.00      0.00      0.00        13\n",
      "          24       1.00      0.00      0.00       319\n",
      "          25       0.00      0.00      0.00       735\n",
      "          26       1.00      0.00      0.00        14\n",
      "          27       0.00      0.00      0.00       665\n",
      "          28       1.00      0.00      0.00       178\n",
      "          29       1.00      0.00      0.00       331\n",
      "          30       0.00      1.00      0.00         0\n",
      "          31       1.00      0.00      0.00         2\n",
      "          32       1.00      0.00      0.00        12\n",
      "          33       1.00      0.00      0.00         2\n",
      "          34       0.00      1.00      0.00         0\n",
      "          35       0.25      0.02      0.03       944\n",
      "          36       1.00      0.00      0.00         2\n",
      "          37       1.00      0.00      0.00         9\n",
      "          38       1.00      0.00      0.00         4\n",
      "          39       1.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.35     22543\n",
      "   macro avg       0.58      0.07      0.02     22543\n",
      "weighted avg       0.44      0.35      0.29     22543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- FGSM Attack with Mask ---\")\n",
    "for eps in [4.0]: \n",
    "    fgsm = FastGradientMethod(estimator=classifier, eps=eps)\n",
    "    X_test_fgsm_adv = fgsm.generate(x=X_test_scaled)\n",
    "    X_test_fgsm_adv = apply_static_mask(X_test_scaled, X_test_fgsm_adv, static_mask)\n",
    "    X_test_fgsm_adv = np.clip(X_test_fgsm_adv, -3, 3)  \n",
    "    y_pred_fgsm_encoded = model.predict(X_test_fgsm_adv).argmax(axis=1)\n",
    "    fgsm_accuracy = accuracy_score(y_test_encoded, y_pred_fgsm_encoded)\n",
    "    print(f\"FGSM Adversarial Accuracy (eps={eps}):\", fgsm_accuracy)\n",
    "    print(\"FGSM Classification Report:\\n\", \n",
    "          classification_report(y_test_encoded, y_pred_fgsm_encoded,zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580de0cd-2d12-463f-8aae-fa960c8fe7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PGD Attack with Static Mask ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 19:08:50.637195: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step\n",
      "PGD Adversarial Accuracy (with masking): 0.3210309186887282\n",
      "PGD Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       737\n",
      "           1       1.00      0.00      0.00       359\n",
      "           2       1.00      0.00      0.00        20\n",
      "           3       1.00      0.00      0.00         3\n",
      "           4       1.00      0.00      0.00      1231\n",
      "           5       1.00      0.00      0.00       133\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00       141\n",
      "           8       1.00      0.00      0.00         7\n",
      "           9       1.00      0.00      0.00         2\n",
      "          10       1.00      0.00      0.00       293\n",
      "          11       1.00      0.00      0.00       996\n",
      "          12       0.00      0.00      0.00        18\n",
      "          13       1.00      0.00      0.00        17\n",
      "          14       0.56      0.31      0.40      4656\n",
      "          15       1.00      0.00      0.00        73\n",
      "          16       0.53      0.58      0.55      9711\n",
      "          17       1.00      0.00      0.00         2\n",
      "          18       1.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00        41\n",
      "          20       0.03      0.99      0.05       157\n",
      "          21       1.00      0.00      0.00       685\n",
      "          22       1.00      0.00      0.00        15\n",
      "          23       0.00      0.00      0.00        13\n",
      "          24       1.00      0.00      0.00       319\n",
      "          25       0.00      0.00      0.00       735\n",
      "          26       1.00      0.00      0.00        14\n",
      "          27       1.00      0.00      0.00       665\n",
      "          28       1.00      0.00      0.00       178\n",
      "          29       1.00      0.00      0.00       331\n",
      "          31       1.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00        12\n",
      "          33       1.00      0.00      0.00         2\n",
      "          35       1.00      0.00      0.00       944\n",
      "          36       1.00      0.00      0.00         2\n",
      "          37       1.00      0.00      0.00         9\n",
      "          38       1.00      0.00      0.00         4\n",
      "          39       1.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.32     22543\n",
      "   macro avg       0.77      0.05      0.03     22543\n",
      "weighted avg       0.66      0.32      0.32     22543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- PGD Attack with Static Mask ---\")\n",
    "pgd = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    norm=np.inf,\n",
    "    eps=3.0,\n",
    "    eps_step=0.02,\n",
    "    max_iter=100,\n",
    "    targeted=False\n",
    ")\n",
    "X_test_pgd_adv = pgd.generate(x=X_test_scaled)\n",
    "X_test_pgd_adv = apply_static_mask(X_test_scaled, X_test_pgd_adv, static_mask)\n",
    "X_test_pgd_adv = np.clip(X_test_pgd_adv, -3, 3)\n",
    "y_pred_pgd_encoded = model.predict(X_test_pgd_adv).argmax(axis=1)\n",
    "pgd_accuracy = accuracy_score(y_test_encoded, y_pred_pgd_encoded)\n",
    "print(\"PGD Adversarial Accuracy (with masking):\", pgd_accuracy)\n",
    "print(\"PGD Classification Report:\\n\", \n",
    "      classification_report(y_test_encoded, y_pred_pgd_encoded,zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77706a0e-5077-41aa-93ac-336e2e05f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Carlini & Wagner Attack with Static Mask ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b13397bd72b4561b590210a59829de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step\n",
      "C&W Adversarial Accuracy (with masking): 0.38\n",
      "C&W Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         3\n",
      "           1       1.00      0.00      0.00         1\n",
      "           2       1.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00        10\n",
      "           5       1.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "          10       1.00      0.00      0.00         1\n",
      "          11       1.00      0.00      0.00        10\n",
      "          14       0.52      0.23      0.32        53\n",
      "          15       1.00      0.00      0.00         2\n",
      "          16       0.70      0.75      0.72        85\n",
      "          19       1.00      0.00      0.00         2\n",
      "          20       0.00      1.00      0.00         0\n",
      "          21       1.00      0.00      0.00        10\n",
      "          22       1.00      0.00      0.00         1\n",
      "          24       1.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         5\n",
      "          27       1.00      0.00      0.00         4\n",
      "          28       1.00      0.00      0.00         2\n",
      "          29       1.00      0.00      0.00         2\n",
      "          35       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.38       200\n",
      "   macro avg       0.82      0.09      0.05       200\n",
      "weighted avg       0.71      0.38      0.39       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Carlini & Wagner Attack with Static Mask ---\")\n",
    "cw = CarliniL2Method(\n",
    "    classifier=classifier,\n",
    "    confidence=2.0,\n",
    "    targeted=False,\n",
    "    max_iter=100,\n",
    "    learning_rate=0.01,\n",
    "    binary_search_steps=5\n",
    ")\n",
    "X_test_cw_adv = cw.generate(x=X_test_scaled[:200])  \n",
    "X_test_cw_adv = apply_static_mask(X_test_scaled[:200], X_test_cw_adv, static_mask[:200])\n",
    "X_test_cw_adv = np.clip(X_test_cw_adv, -3, 3)\n",
    "y_pred_cw_encoded = model.predict(X_test_cw_adv).argmax(axis=1)\n",
    "cw_accuracy = accuracy_score(y_test_encoded[:200], y_pred_cw_encoded)\n",
    "print(\"C&W Adversarial Accuracy (with masking):\", cw_accuracy)\n",
    "print(\"C&W Classification Report:\\n\", \n",
    "      classification_report(y_test_encoded[:200], y_pred_cw_encoded,zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3433cdf7-48e1-4882-88eb-58bd0bd97c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data shape: (125972, 28), (125972,)\n",
      "Resampled training data shape: (1548866, 28), (1548866,)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 452us/step - accuracy: 0.9478 - loss: 0.1525 - val_accuracy: 0.2237 - val_loss: 16.0586\n",
      "Epoch 2/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 424us/step - accuracy: 0.9806 - loss: 0.0608 - val_accuracy: 0.2605 - val_loss: 23.2003\n",
      "Epoch 3/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 423us/step - accuracy: 0.9826 - loss: 0.0549 - val_accuracy: 0.1401 - val_loss: 34.5854\n",
      "Epoch 4/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 426us/step - accuracy: 0.9847 - loss: 0.0495 - val_accuracy: 0.1093 - val_loss: 36.6616\n",
      "Epoch 5/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 423us/step - accuracy: 0.9849 - loss: 0.0496 - val_accuracy: 0.2715 - val_loss: 44.8087\n",
      "Epoch 6/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 428us/step - accuracy: 0.9855 - loss: 0.0481 - val_accuracy: 0.0940 - val_loss: 54.7231\n",
      "Epoch 7/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 433us/step - accuracy: 0.9861 - loss: 0.0455 - val_accuracy: 0.1391 - val_loss: 67.1193\n",
      "Epoch 8/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 450us/step - accuracy: 0.9854 - loss: 0.0487 - val_accuracy: 0.1001 - val_loss: 64.5866\n",
      "Epoch 9/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 432us/step - accuracy: 0.9859 - loss: 0.0469 - val_accuracy: 0.0301 - val_loss: 86.8797\n",
      "Epoch 10/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 437us/step - accuracy: 0.9860 - loss: 0.0468 - val_accuracy: 0.2249 - val_loss: 83.0019\n",
      "Epoch 11/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 403us/step - accuracy: 0.9859 - loss: 0.0468 - val_accuracy: 0.0963 - val_loss: 115.6916\n",
      "Epoch 12/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 410us/step - accuracy: 0.9854 - loss: 0.0484 - val_accuracy: 0.2985 - val_loss: 143.5779\n",
      "Epoch 13/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 447us/step - accuracy: 0.9855 - loss: 0.0508 - val_accuracy: 0.2906 - val_loss: 168.1776\n",
      "Epoch 14/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 451us/step - accuracy: 0.9865 - loss: 0.0467 - val_accuracy: 0.2995 - val_loss: 188.0987\n",
      "Epoch 15/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 415us/step - accuracy: 0.9855 - loss: 0.0494 - val_accuracy: 0.3145 - val_loss: 247.8383\n",
      "Epoch 16/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 417us/step - accuracy: 0.9868 - loss: 0.0475 - val_accuracy: 0.1459 - val_loss: 176.2530\n",
      "Epoch 17/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 401us/step - accuracy: 0.9858 - loss: 0.0498 - val_accuracy: 0.1760 - val_loss: 298.5218\n",
      "Epoch 18/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 408us/step - accuracy: 0.9866 - loss: 0.0461 - val_accuracy: 0.1361 - val_loss: 359.2427\n",
      "Epoch 19/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 408us/step - accuracy: 0.9865 - loss: 0.0475 - val_accuracy: 0.1873 - val_loss: 424.0869\n",
      "Epoch 20/20\n",
      "\u001b[1m48403/48403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 439us/step - accuracy: 0.9864 - loss: 0.0486 - val_accuracy: 0.1467 - val_loss: 564.7159\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, QuantileTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "X_train_scaled = quantile_transformer.fit_transform(X_train_scaled)\n",
    "X_test_scaled = quantile_transformer.transform(X_test_scaled)\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "class_counts = Counter(y_train_encoded)\n",
    "min_class_size = min(class_counts.values())\n",
    "smote = SMOTE(random_state=42, k_neighbors=min(min_class_size - 1, 5))\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train_encoded)\n",
    "\n",
    "print(f\"Original training data shape: {X_train_scaled.shape}, {y_train_encoded.shape}\")\n",
    "print(f\"Resampled training data shape: {X_train_resampled.shape}, {y_train_resampled.shape}\")\n",
    "num_classes = len(label_encoder.classes_) \n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax') \n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = mlp_model.fit(\n",
    "    X_train_resampled, y_train_resampled, \n",
    "    epochs=20, batch_size=32, \n",
    "    validation_data=(X_test_scaled, y_test_encoded)\n",
    ")\n",
    "y_pred_encoded = mlp_model.predict(X_test_scaled).argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd26d7-c38a-40ea-bde5-6669420bf0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step\n",
      "MLP Model Accuracy on Clean Data: 0.14669742270327818\n",
      "Classification Report on Clean Data with Attack Names:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        apache2       1.00      0.00      0.00       737\n",
      "           back       1.00      0.00      0.00       359\n",
      "buffer_overflow       0.00      0.00      0.00        20\n",
      "      ftp_write       1.00      0.00      0.00         3\n",
      "   guess_passwd       1.00      0.00      0.00      1231\n",
      "     httptunnel       1.00      0.00      0.00       133\n",
      "           imap       1.00      0.00      0.00         1\n",
      "        ipsweep       0.04      0.03      0.03       141\n",
      "           land       1.00      0.00      0.00         7\n",
      "     loadmodule       1.00      0.00      0.00         2\n",
      "       mailbomb       1.00      0.00      0.00       293\n",
      "          mscan       1.00      0.00      0.00       996\n",
      "       multihop       1.00      0.00      0.00        18\n",
      "          named       1.00      0.00      0.00        17\n",
      "        neptune       0.62      0.31      0.41      4656\n",
      "           nmap       0.00      0.00      0.00        73\n",
      "         normal       0.32      0.18      0.23      9711\n",
      "           perl       1.00      0.00      0.00         2\n",
      "            phf       1.00      0.00      0.00         2\n",
      "            pod       1.00      0.00      0.00        41\n",
      "      portsweep       0.02      0.82      0.04       157\n",
      "   processtable       1.00      0.00      0.00       685\n",
      "             ps       1.00      0.00      0.00        15\n",
      "        rootkit       0.00      0.00      0.00        13\n",
      "          saint       1.00      0.00      0.00       319\n",
      "          satan       0.00      0.03      0.01       735\n",
      "       sendmail       1.00      0.00      0.00        14\n",
      "          smurf       0.00      0.00      0.00       665\n",
      "  snmpgetattack       1.00      0.00      0.00       178\n",
      "      snmpguess       1.00      0.00      0.00       331\n",
      "            spy       0.00      1.00      0.00         0\n",
      "      sqlattack       1.00      0.00      0.00         2\n",
      "       teardrop       1.00      0.00      0.00        12\n",
      "       udpstorm       1.00      0.00      0.00         2\n",
      "    warezmaster       0.11      0.00      0.00       944\n",
      "           worm       1.00      0.00      0.00         2\n",
      "          xlock       1.00      0.00      0.00         9\n",
      "         xsnoop       1.00      0.00      0.00         4\n",
      "          xterm       1.00      0.00      0.00        13\n",
      "\n",
      "       accuracy                           0.15     22543\n",
      "      macro avg       0.75      0.06      0.02     22543\n",
      "   weighted avg       0.51      0.15      0.18     22543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = mlp_model.predict(X_test_scaled).argmax(axis=1)\n",
    "clean_accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "clean_class_report = classification_report(y_test_encoded, y_pred, zero_division=1)\n",
    "clean_conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "decoded_class_report = classification_report(y_test_labels, y_pred_labels, zero_division=1)\n",
    "decoded_conf_matrix = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "print(\"MLP Model Accuracy on Clean Data:\", clean_accuracy)\n",
    "print(\"Classification Report on Clean Data with Attack Names:\\n\", decoded_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ce2af-a6e1-48d4-9364-bae0bbb6b9e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent, CarliniL2Method\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=mlp_model,\n",
    "    nb_classes=len(label_encoder.classes_),\n",
    "    input_shape=(X_train_scaled.shape[1],),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n",
    "\n",
    "critical_features = [19, 23, 26, 2, 20, 27] \n",
    "def create_static_mask(data, critical_features):\n",
    "    \"\"\"\n",
    "    Creates a mask with 1s for critical features and 0s elsewhere.\n",
    "    Args:\n",
    "        data: Dataset (numpy array or DataFrame).\n",
    "        critical_features: List of critical feature indices.\n",
    "    Returns:\n",
    "        Mask of the same shape as data, with 1s for critical features.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(data)  \n",
    "    mask[:, critical_features] = 1  \n",
    "    return mask\n",
    "static_mask = create_static_mask(X_test_scaled, critical_features)\n",
    "def apply_static_mask(X_original, X_adv, mask):\n",
    "    \"\"\"\n",
    "    Applies a static mask to perturb only selected features.\n",
    "    Args:\n",
    "        X_original: Original input data.\n",
    "        X_adv: Adversarial examples.\n",
    "        mask: Mask indicating which features to perturb (1 = perturb, 0 = keep original).\n",
    "    Returns:\n",
    "        Masked adversarial examples.\n",
    "    \"\"\"\n",
    "    return X_original + (X_adv - X_original) * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680eae8-53cc-4128-be54-970ac5bcb3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FGSM Attack with Dynamic Masking ---\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step\n",
      "FGSM Adversarial Accuracy (eps=3.0): 0.2854101051324136\n",
      "FGSM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       737\n",
      "           1       1.00      0.00      0.00       359\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       1.00      0.00      0.00         3\n",
      "           4       1.00      0.00      0.00      1231\n",
      "           5       1.00      0.00      0.00       133\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00       141\n",
      "           8       1.00      0.00      0.00         7\n",
      "           9       1.00      0.00      0.00         2\n",
      "          10       1.00      0.00      0.00       293\n",
      "          11       1.00      0.00      0.00       996\n",
      "          12       0.00      0.00      0.00        18\n",
      "          13       1.00      0.00      0.00        17\n",
      "          14       0.63      0.29      0.40      4656\n",
      "          15       0.03      0.81      0.05        73\n",
      "          16       0.53      0.47      0.50      9711\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       1.00      0.00      0.00        41\n",
      "          20       0.03      0.86      0.06       157\n",
      "          21       1.00      0.00      0.00       685\n",
      "          22       1.00      0.00      0.00        15\n",
      "          23       0.00      0.00      0.00        13\n",
      "          24       1.00      0.00      0.00       319\n",
      "          25       0.19      0.40      0.26       735\n",
      "          26       1.00      0.00      0.00        14\n",
      "          27       0.00      0.00      0.00       665\n",
      "          28       1.00      0.00      0.00       178\n",
      "          29       1.00      0.00      0.00       331\n",
      "          31       1.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00        12\n",
      "          33       1.00      0.00      0.00         2\n",
      "          35       0.03      0.00      0.00       944\n",
      "          36       1.00      0.00      0.00         2\n",
      "          37       1.00      0.00      0.00         9\n",
      "          38       1.00      0.00      0.00         4\n",
      "          39       1.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.29     22543\n",
      "   macro avg       0.64      0.07      0.03     22543\n",
      "weighted avg       0.61      0.29      0.31     22543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- FGSM Attack with Dynamic Masking ---\")\n",
    "for eps in [3.0]:  \n",
    "    fgsm = FastGradientMethod(estimator=classifier, eps=eps)\n",
    "    X_test_fgsm_adv = fgsm.generate(x=X_test_scaled)\n",
    "    X_test_fgsm_adv = apply_static_mask(X_test_scaled, X_test_fgsm_adv, static_mask)\n",
    "    X_test_fgsm_adv = np.clip(X_test_fgsm_adv, -3, 3)  \n",
    "    y_pred_fgsm_encoded = mlp_model.predict(X_test_fgsm_adv).argmax(axis=1)\n",
    "    fgsm_accuracy = accuracy_score(y_test_encoded, y_pred_fgsm_encoded)\n",
    "    print(f\"FGSM Adversarial Accuracy (eps={eps}):\", fgsm_accuracy)\n",
    "    print(\"FGSM Classification Report:\\n\", \n",
    "          classification_report(y_test_encoded, y_pred_fgsm_encoded,zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11210d9d-b83c-4be8-8080-d7040b2e2ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd1ae35-e6f9-4f46-a01e-3174ed6f38b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PGD Attack with Dynamic Masking ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step\n",
      "PGD Adversarial Accuracy (with masking): 0.18036641085924676\n",
      "PGD Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       737\n",
      "           1       1.00      0.00      0.00       359\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       1.00      0.00      0.00         3\n",
      "           4       1.00      0.00      0.00      1231\n",
      "           5       1.00      0.00      0.00       133\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.04      0.01      0.02       141\n",
      "           8       1.00      0.00      0.00         7\n",
      "           9       1.00      0.00      0.00         2\n",
      "          10       1.00      0.00      0.00       293\n",
      "          11       1.00      0.00      0.00       996\n",
      "          12       0.00      0.00      0.00        18\n",
      "          13       1.00      0.00      0.00        17\n",
      "          14       0.53      0.31      0.39      4656\n",
      "          15       0.00      0.00      0.00        73\n",
      "          16       0.34      0.20      0.25      9711\n",
      "          17       1.00      0.00      0.00         2\n",
      "          18       1.00      0.00      0.00         2\n",
      "          19       1.00      0.00      0.00        41\n",
      "          20       0.02      0.86      0.03       157\n",
      "          21       1.00      0.00      0.00       685\n",
      "          22       1.00      0.00      0.00        15\n",
      "          23       0.00      0.00      0.00        13\n",
      "          24       1.00      0.00      0.00       319\n",
      "          25       0.06      0.41      0.11       735\n",
      "          26       1.00      0.00      0.00        14\n",
      "          27       0.85      0.31      0.46       665\n",
      "          28       1.00      0.00      0.00       178\n",
      "          29       1.00      0.00      0.00       331\n",
      "          30       0.00      1.00      0.00         0\n",
      "          31       1.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00        12\n",
      "          33       1.00      0.00      0.00         2\n",
      "          35       0.14      0.00      0.00       944\n",
      "          36       1.00      0.00      0.00         2\n",
      "          37       1.00      0.00      0.00         9\n",
      "          38       1.00      0.00      0.00         4\n",
      "          39       1.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.18     22543\n",
      "   macro avg       0.69      0.08      0.03     22543\n",
      "weighted avg       0.53      0.18      0.21     22543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- PGD Attack with Dynamic Masking ---\")\n",
    "pgd = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    norm=np.inf,\n",
    "    eps=3.0,\n",
    "    eps_step=0.02,\n",
    "    max_iter=100,\n",
    "    targeted=False\n",
    ")\n",
    "X_test_pgd_adv = pgd.generate(x=X_test_scaled)\n",
    "X_test_pgd_adv = apply_static_mask(X_test_scaled, X_test_pgd_adv, static_mask)\n",
    "X_test_pgd_adv = np.clip(X_test_pgd_adv, -3, 3)\n",
    "y_pred_pgd_encoded = mlp_model.predict(X_test_pgd_adv).argmax(axis=1)\n",
    "pgd_accuracy = accuracy_score(y_test_encoded, y_pred_pgd_encoded)\n",
    "print(\"PGD Adversarial Accuracy (with masking):\", pgd_accuracy)\n",
    "print(\"PGD Classification Report:\\n\", \n",
    "      classification_report(y_test_encoded, y_pred_pgd_encoded,zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf1da3-156d-4881-8fdc-2958d02ac3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Carlini & Wagner Attack with Dynamic Masking ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f8dbc2ecfe49179990443c9fd11431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step\n",
      "C&W Adversarial Accuracy (with masking): 0.13\n",
      "C&W Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         3\n",
      "           1       1.00      0.00      0.00         1\n",
      "           2       1.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00        10\n",
      "           5       1.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "          10       1.00      0.00      0.00         1\n",
      "          11       1.00      0.00      0.00        10\n",
      "          14       0.52      0.23      0.32        53\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.28      0.14      0.19        85\n",
      "          19       1.00      0.00      0.00         2\n",
      "          20       0.00      1.00      0.00         0\n",
      "          21       1.00      0.00      0.00        10\n",
      "          22       1.00      0.00      0.00         1\n",
      "          23       0.00      1.00      0.00         0\n",
      "          24       1.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         5\n",
      "          27       1.00      0.50      0.67         4\n",
      "          28       1.00      0.00      0.00         2\n",
      "          29       1.00      0.00      0.00         2\n",
      "          35       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.13       200\n",
      "   macro avg       0.72      0.13      0.05       200\n",
      "weighted avg       0.53      0.13      0.18       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Carlini & Wagner Attack with Masking ---\")\n",
    "cw = CarliniL2Method(\n",
    "    classifier=classifier,\n",
    "    confidence=2.0,\n",
    "    targeted=False,\n",
    "    max_iter=100,\n",
    "    learning_rate=0.01,\n",
    "    binary_search_steps=5\n",
    ")\n",
    "X_test_cw_adv = cw.generate(x=X_test_scaled[:200]) \n",
    "X_test_cw_adv = apply_static_mask(X_test_scaled[:200], X_test_cw_adv, static_mask[:200])\n",
    "X_test_cw_adv = np.clip(X_test_cw_adv, -3, 3)\n",
    "y_pred_cw_encoded = mlp_model.predict(X_test_cw_adv).argmax(axis=1)\n",
    "cw_accuracy = accuracy_score(y_test_encoded[:200], y_pred_cw_encoded)\n",
    "print(\"C&W Adversarial Accuracy (with masking):\", cw_accuracy)\n",
    "print(\"C&W Classification Report:\\n\", \n",
    "      classification_report(y_test_encoded[:200], y_pred_cw_encoded,zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c78224-3441-4b7d-948d-178f58c7d5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
