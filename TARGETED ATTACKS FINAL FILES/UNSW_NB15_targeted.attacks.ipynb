{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e78939-d3ea-444f-8148-580a81f6ee46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6216e408-ff98-4d09-864b-29d7adaa804b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/marlenawasiak/Desktop/Data_Collection/UNSW_NB15_training-set.csv')\n",
    "test_data = pd.read_csv('/Users/marlenawasiak/Desktop/Data_Collection/UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee4bc3-7d5f-44cc-8a57-7e0554a49d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['attack_cat'])\n",
    "y_train = train_data['attack_cat']\n",
    "X_test = test_data.drop(columns=['attack_cat'])\n",
    "y_test = test_data['attack_cat']\n",
    "categorical_features = ['proto', 'service', 'state']\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled) \n",
    "X_test_scaled = scaler.transform(X_test)                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbdb1d-c373-4138-9301-556f7de8f457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 592us/step - accuracy: 0.6430 - loss: 0.8994 - val_accuracy: 0.6394 - val_loss: 1.3868\n",
      "Epoch 2/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 622us/step - accuracy: 0.7240 - loss: 0.6669 - val_accuracy: 0.6317 - val_loss: 2.1254\n",
      "Epoch 3/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 635us/step - accuracy: 0.7337 - loss: 0.6376 - val_accuracy: 0.7726 - val_loss: 1.6026\n",
      "Epoch 4/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 601us/step - accuracy: 0.7381 - loss: 0.6215 - val_accuracy: 0.7698 - val_loss: 1.8644\n",
      "Epoch 5/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 652us/step - accuracy: 0.7421 - loss: 0.6072 - val_accuracy: 0.7093 - val_loss: 2.5264\n",
      "Epoch 6/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 644us/step - accuracy: 0.7455 - loss: 0.5999 - val_accuracy: 0.7764 - val_loss: 2.3490\n",
      "Epoch 7/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 639us/step - accuracy: 0.7471 - loss: 0.5928 - val_accuracy: 0.7909 - val_loss: 2.7585\n",
      "Epoch 8/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 654us/step - accuracy: 0.7501 - loss: 0.5836 - val_accuracy: 0.7862 - val_loss: 2.9562\n",
      "Epoch 9/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 598us/step - accuracy: 0.7516 - loss: 0.5794 - val_accuracy: 0.7574 - val_loss: 3.5629\n",
      "Epoch 10/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 616us/step - accuracy: 0.7518 - loss: 0.5781 - val_accuracy: 0.7620 - val_loss: 3.5647\n",
      "Epoch 11/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 653us/step - accuracy: 0.7525 - loss: 0.5729 - val_accuracy: 0.7824 - val_loss: 3.3734\n",
      "Epoch 12/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 608us/step - accuracy: 0.7546 - loss: 0.5711 - val_accuracy: 0.7664 - val_loss: 3.6899\n",
      "Epoch 13/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 628us/step - accuracy: 0.7565 - loss: 0.5649 - val_accuracy: 0.7837 - val_loss: 3.5239\n",
      "Epoch 14/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 645us/step - accuracy: 0.7558 - loss: 0.5659 - val_accuracy: 0.7238 - val_loss: 5.0181\n",
      "Epoch 15/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 600us/step - accuracy: 0.7580 - loss: 0.5595 - val_accuracy: 0.7605 - val_loss: 4.0745\n",
      "Epoch 16/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 706us/step - accuracy: 0.7577 - loss: 0.5594 - val_accuracy: 0.7710 - val_loss: 4.0823\n",
      "Epoch 17/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 580us/step - accuracy: 0.7593 - loss: 0.5585 - val_accuracy: 0.7580 - val_loss: 4.3284\n",
      "Epoch 18/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 613us/step - accuracy: 0.7593 - loss: 0.5552 - val_accuracy: 0.7504 - val_loss: 4.1588\n",
      "Epoch 19/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - accuracy: 0.7591 - loss: 0.5540 - val_accuracy: 0.7488 - val_loss: 5.0879\n",
      "Epoch 20/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 523us/step - accuracy: 0.7603 - loss: 0.5514 - val_accuracy: 0.6712 - val_loss: 5.7274\n",
      "Epoch 21/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 588us/step - accuracy: 0.7611 - loss: 0.5483 - val_accuracy: 0.7199 - val_loss: 5.4443\n",
      "Epoch 22/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 594us/step - accuracy: 0.7622 - loss: 0.5487 - val_accuracy: 0.6294 - val_loss: 7.7864\n",
      "Epoch 23/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 653us/step - accuracy: 0.7615 - loss: 0.5494 - val_accuracy: 0.7221 - val_loss: 5.5239\n",
      "Epoch 24/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 603us/step - accuracy: 0.7616 - loss: 0.5492 - val_accuracy: 0.7344 - val_loss: 5.6475\n",
      "Epoch 25/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 595us/step - accuracy: 0.7631 - loss: 0.5461 - val_accuracy: 0.7060 - val_loss: 5.3209\n",
      "Epoch 26/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 608us/step - accuracy: 0.7637 - loss: 0.5439 - val_accuracy: 0.7350 - val_loss: 5.4492\n",
      "Epoch 27/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 613us/step - accuracy: 0.7641 - loss: 0.5437 - val_accuracy: 0.7604 - val_loss: 5.5433\n",
      "Epoch 28/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 598us/step - accuracy: 0.7644 - loss: 0.5427 - val_accuracy: 0.7196 - val_loss: 5.8874\n",
      "Epoch 29/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 612us/step - accuracy: 0.7649 - loss: 0.5413 - val_accuracy: 0.7255 - val_loss: 5.6579\n",
      "Epoch 30/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 580us/step - accuracy: 0.7654 - loss: 0.5415 - val_accuracy: 0.7646 - val_loss: 4.7990\n",
      "Epoch 31/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 589us/step - accuracy: 0.7644 - loss: 0.5411 - val_accuracy: 0.6621 - val_loss: 7.8823\n",
      "Epoch 32/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 599us/step - accuracy: 0.7644 - loss: 0.5402 - val_accuracy: 0.6460 - val_loss: 10.7147\n",
      "Epoch 33/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 583us/step - accuracy: 0.7652 - loss: 0.5392 - val_accuracy: 0.6255 - val_loss: 12.3863\n",
      "Epoch 34/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 680us/step - accuracy: 0.7673 - loss: 0.5409 - val_accuracy: 0.7213 - val_loss: 6.8794\n",
      "Epoch 35/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 622us/step - accuracy: 0.7666 - loss: 0.5371 - val_accuracy: 0.6737 - val_loss: 8.7029\n",
      "Epoch 36/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 623us/step - accuracy: 0.7677 - loss: 0.5352 - val_accuracy: 0.6594 - val_loss: 9.1307\n",
      "Epoch 37/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 607us/step - accuracy: 0.7678 - loss: 0.5336 - val_accuracy: 0.6915 - val_loss: 7.2052\n",
      "Epoch 38/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 553us/step - accuracy: 0.7683 - loss: 0.5354 - val_accuracy: 0.6783 - val_loss: 8.6852\n",
      "Epoch 39/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 587us/step - accuracy: 0.7681 - loss: 0.5339 - val_accuracy: 0.6568 - val_loss: 8.0603\n",
      "Epoch 40/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 593us/step - accuracy: 0.7683 - loss: 0.5314 - val_accuracy: 0.6791 - val_loss: 9.4660\n",
      "Epoch 41/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 593us/step - accuracy: 0.7693 - loss: 0.5315 - val_accuracy: 0.6267 - val_loss: 12.1726\n",
      "Epoch 42/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 625us/step - accuracy: 0.7698 - loss: 0.5312 - val_accuracy: 0.6388 - val_loss: 9.0162\n",
      "Epoch 43/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 587us/step - accuracy: 0.7686 - loss: 0.5363 - val_accuracy: 0.6586 - val_loss: 9.0969\n",
      "Epoch 44/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 602us/step - accuracy: 0.7701 - loss: 0.5320 - val_accuracy: 0.6320 - val_loss: 9.8401\n",
      "Epoch 45/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 611us/step - accuracy: 0.7692 - loss: 0.5363 - val_accuracy: 0.6478 - val_loss: 9.6130\n",
      "Epoch 46/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 609us/step - accuracy: 0.7706 - loss: 0.5318 - val_accuracy: 0.6284 - val_loss: 10.1135\n",
      "Epoch 47/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 640us/step - accuracy: 0.7697 - loss: 0.5328 - val_accuracy: 0.6176 - val_loss: 15.6436\n",
      "Epoch 48/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 751us/step - accuracy: 0.7705 - loss: 0.5294 - val_accuracy: 0.6348 - val_loss: 10.8301\n",
      "Epoch 49/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 737us/step - accuracy: 0.7700 - loss: 0.5332 - val_accuracy: 0.6542 - val_loss: 9.5570\n",
      "Epoch 50/50\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 668us/step - accuracy: 0.7710 - loss: 0.5288 - val_accuracy: 0.6789 - val_loss: 8.5386\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_resampled.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), class_weight=class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ad789-3961-48bc-9e5c-4c5cf5b6b25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2573/2573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301us/step\n",
      "Test Accuracy: 0.6788976339697809\n",
      "Classification Report - Clean Data:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.06      0.21      0.09       677\n",
      "      Backdoor       0.05      0.55      0.09       583\n",
      "           DoS       0.25      0.11      0.15      4089\n",
      "      Exploits       0.35      0.50      0.41     11132\n",
      "       Fuzzers       0.49      0.64      0.55      6062\n",
      "       Generic       1.00      0.33      0.50     18871\n",
      "        Normal       1.00      1.00      1.00     37000\n",
      "Reconnaissance       0.58      0.62      0.60      3496\n",
      "     Shellcode       0.20      0.43      0.27       378\n",
      "         Worms       0.12      0.20      0.15        44\n",
      "\n",
      "      accuracy                           0.68     82332\n",
      "     macro avg       0.41      0.46      0.38     82332\n",
      "  weighted avg       0.80      0.68      0.70     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_encoded = model.predict(X_test_scaled).argmax(axis=1)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "class_report = classification_report(\n",
    "    y_test, \n",
    "    y_pred_encoded, \n",
    "    labels=range(len(label_encoder.classes_)), \n",
    "    target_names=label_encoder.classes_, \n",
    "    zero_division=1\n",
    ")\n",
    "print(\"Classification Report - Clean Data:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f69e1-2d44-40ae-87a8-e09f887a1853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before augmentation: (175341, 193) (175341,)\n",
      "After SMOTE augmentation: (560000, 193) (560000,)\n",
      "After adding noise: (1120000, 193) (1120000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 498us/step - accuracy: 0.6897 - loss: 0.7856 - val_accuracy: 0.8215 - val_loss: 0.6884\n",
      "Epoch 2/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 510us/step - accuracy: 0.7607 - loss: 0.6037 - val_accuracy: 0.7370 - val_loss: 1.6781\n",
      "Epoch 3/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 487us/step - accuracy: 0.7744 - loss: 0.5721 - val_accuracy: 0.7420 - val_loss: 1.8948\n",
      "Epoch 4/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 485us/step - accuracy: 0.7805 - loss: 0.5571 - val_accuracy: 0.7446 - val_loss: 2.3958\n",
      "Epoch 5/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 464us/step - accuracy: 0.7859 - loss: 0.5445 - val_accuracy: 0.6139 - val_loss: 6.5876\n",
      "Epoch 6/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 486us/step - accuracy: 0.7889 - loss: 0.5361 - val_accuracy: 0.6023 - val_loss: 6.7252\n",
      "Epoch 7/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 456us/step - accuracy: 0.7930 - loss: 0.5270 - val_accuracy: 0.6820 - val_loss: 3.9844\n",
      "Epoch 8/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 504us/step - accuracy: 0.7952 - loss: 0.5219 - val_accuracy: 0.6925 - val_loss: 4.1508\n",
      "Epoch 9/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 459us/step - accuracy: 0.7966 - loss: 0.5170 - val_accuracy: 0.6233 - val_loss: 5.3509\n",
      "Epoch 10/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 489us/step - accuracy: 0.7989 - loss: 0.5114 - val_accuracy: 0.7177 - val_loss: 4.1241\n",
      "Epoch 11/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 472us/step - accuracy: 0.8009 - loss: 0.5114 - val_accuracy: 0.7127 - val_loss: 5.5827\n",
      "Epoch 12/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 482us/step - accuracy: 0.8023 - loss: 0.5046 - val_accuracy: 0.7247 - val_loss: 6.0872\n",
      "Epoch 13/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 476us/step - accuracy: 0.8025 - loss: 0.5028 - val_accuracy: 0.7291 - val_loss: 7.7809\n",
      "Epoch 14/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 476us/step - accuracy: 0.8040 - loss: 0.5000 - val_accuracy: 0.7238 - val_loss: 10.3900\n",
      "Epoch 15/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 475us/step - accuracy: 0.8062 - loss: 0.4958 - val_accuracy: 0.6852 - val_loss: 10.5261\n",
      "Epoch 16/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 483us/step - accuracy: 0.8065 - loss: 0.4925 - val_accuracy: 0.6837 - val_loss: 9.9092\n",
      "Epoch 17/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 464us/step - accuracy: 0.8074 - loss: 0.4940 - val_accuracy: 0.7222 - val_loss: 9.7598\n",
      "Epoch 18/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 490us/step - accuracy: 0.8082 - loss: 0.4896 - val_accuracy: 0.6464 - val_loss: 12.3141\n",
      "Epoch 19/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 499us/step - accuracy: 0.8089 - loss: 0.4879 - val_accuracy: 0.7438 - val_loss: 9.6616\n",
      "Epoch 20/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 506us/step - accuracy: 0.8094 - loss: 0.4862 - val_accuracy: 0.6471 - val_loss: 13.6195\n",
      "Epoch 21/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 490us/step - accuracy: 0.8101 - loss: 0.4851 - val_accuracy: 0.6915 - val_loss: 6.8675\n",
      "Epoch 22/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 482us/step - accuracy: 0.8112 - loss: 0.4833 - val_accuracy: 0.6159 - val_loss: 14.4644\n",
      "Epoch 23/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 494us/step - accuracy: 0.8122 - loss: 0.4814 - val_accuracy: 0.7139 - val_loss: 9.9523\n",
      "Epoch 24/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 507us/step - accuracy: 0.8127 - loss: 0.4797 - val_accuracy: 0.6056 - val_loss: 11.7861\n",
      "Epoch 25/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 483us/step - accuracy: 0.8126 - loss: 0.4772 - val_accuracy: 0.6842 - val_loss: 16.5984\n",
      "Epoch 26/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 484us/step - accuracy: 0.8132 - loss: 0.4777 - val_accuracy: 0.7196 - val_loss: 6.2652\n",
      "Epoch 27/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 480us/step - accuracy: 0.8139 - loss: 0.4767 - val_accuracy: 0.7277 - val_loss: 8.4065\n",
      "Epoch 28/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 479us/step - accuracy: 0.8140 - loss: 0.4768 - val_accuracy: 0.6505 - val_loss: 8.6356\n",
      "Epoch 29/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 479us/step - accuracy: 0.8143 - loss: 0.4757 - val_accuracy: 0.7345 - val_loss: 6.2270\n",
      "Epoch 30/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 497us/step - accuracy: 0.8150 - loss: 0.4733 - val_accuracy: 0.6913 - val_loss: 8.1686\n",
      "Epoch 31/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 480us/step - accuracy: 0.8158 - loss: 0.4715 - val_accuracy: 0.7011 - val_loss: 10.4241\n",
      "Epoch 32/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 481us/step - accuracy: 0.8161 - loss: 0.4711 - val_accuracy: 0.7088 - val_loss: 14.4076\n",
      "Epoch 33/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 480us/step - accuracy: 0.8162 - loss: 0.4702 - val_accuracy: 0.7031 - val_loss: 13.9875\n",
      "Epoch 34/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 462us/step - accuracy: 0.8166 - loss: 0.4695 - val_accuracy: 0.6592 - val_loss: 7.3443\n",
      "Epoch 35/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 486us/step - accuracy: 0.8164 - loss: 0.4694 - val_accuracy: 0.7157 - val_loss: 9.9989\n",
      "Epoch 36/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 520us/step - accuracy: 0.8175 - loss: 0.4684 - val_accuracy: 0.7075 - val_loss: 11.9305\n",
      "Epoch 37/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 481us/step - accuracy: 0.8177 - loss: 0.4696 - val_accuracy: 0.7074 - val_loss: 18.2315\n",
      "Epoch 38/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 446us/step - accuracy: 0.8175 - loss: 0.4671 - val_accuracy: 0.7311 - val_loss: 22.1583\n",
      "Epoch 39/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 489us/step - accuracy: 0.8178 - loss: 0.4664 - val_accuracy: 0.6980 - val_loss: 21.4982\n",
      "Epoch 40/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 485us/step - accuracy: 0.8182 - loss: 0.4672 - val_accuracy: 0.6990 - val_loss: 19.4387\n",
      "Epoch 41/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 477us/step - accuracy: 0.8188 - loss: 0.4649 - val_accuracy: 0.7057 - val_loss: 21.5931\n",
      "Epoch 42/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 463us/step - accuracy: 0.8200 - loss: 0.4626 - val_accuracy: 0.6988 - val_loss: 16.6168\n",
      "Epoch 43/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 491us/step - accuracy: 0.8188 - loss: 0.4654 - val_accuracy: 0.7280 - val_loss: 24.2232\n",
      "Epoch 44/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 491us/step - accuracy: 0.8196 - loss: 0.4633 - val_accuracy: 0.6910 - val_loss: 18.8293\n",
      "Epoch 45/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 485us/step - accuracy: 0.8200 - loss: 0.4624 - val_accuracy: 0.7188 - val_loss: 21.2412\n",
      "Epoch 46/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 484us/step - accuracy: 0.8200 - loss: 0.4631 - val_accuracy: 0.7234 - val_loss: 15.1257\n",
      "Epoch 47/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 511us/step - accuracy: 0.8201 - loss: 0.4639 - val_accuracy: 0.6661 - val_loss: 17.5358\n",
      "Epoch 48/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 471us/step - accuracy: 0.8204 - loss: 0.4625 - val_accuracy: 0.7427 - val_loss: 48.4492\n",
      "Epoch 49/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 490us/step - accuracy: 0.8198 - loss: 0.4624 - val_accuracy: 0.7505 - val_loss: 11.6193\n",
      "Epoch 50/50\n",
      "\u001b[1m35000/35000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 491us/step - accuracy: 0.8207 - loss: 0.4605 - val_accuracy: 0.7110 - val_loss: 20.2243\n",
      "\n",
      "Model evaluation on test set:\n",
      "\u001b[1m2573/2573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282us/step - accuracy: 0.6006 - loss: 45.5256\n",
      "Test Loss: 20.22433090209961, Test Accuracy: 0.711011528968811\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "X_train = train_data.drop(columns=['attack_cat'])\n",
    "y_train = train_data['attack_cat']\n",
    "X_test = test_data.drop(columns=['attack_cat'])\n",
    "y_test = test_data['attack_cat']\n",
    "categorical_features = ['proto', 'service', 'state']\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "print(\"Before augmentation:\", X_train.shape, y_train.shape)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE augmentation:\", X_train_resampled.shape, y_train_resampled.shape)\n",
    "noise = np.random.normal(0, 0.01, X_train_resampled.shape)\n",
    "X_train_noisy = X_train_resampled + noise\n",
    "X_train_augmented = np.vstack((X_train_resampled, X_train_noisy))\n",
    "y_train_augmented = np.hstack((y_train_resampled, y_train_resampled))\n",
    "\n",
    "print(\"After adding noise:\", X_train_augmented.shape, y_train_augmented.shape)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_augmented)  \n",
    "X_test_scaled = scaler.transform(X_test)                 \n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', classes=np.unique(y_train_augmented), y=y_train_augmented\n",
    ")\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_augmented, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_data=(X_test_scaled, y_test), \n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "print(\"\\nModel evaluation on test set:\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f701594-1bcf-426b-9a64-f175bea53b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FGSM Attack ---\n",
      "\u001b[1m2573/2573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step\n",
      "FGSM Adversarial Accuracy: 0.526356702132828\n",
      "Classification Report on FGSM Adversarial Examples:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.04      0.03      0.03       677\n",
      "      Backdoor       0.01      0.05      0.01       583\n",
      "           DoS       0.05      0.10      0.06      4089\n",
      "      Exploits       0.39      0.43      0.41     11132\n",
      "       Fuzzers       0.12      0.08      0.09      6062\n",
      "       Generic       0.96      0.03      0.05     18871\n",
      "        Normal       0.78      1.00      0.88     37000\n",
      "Reconnaissance       0.10      0.04      0.06      3496\n",
      "     Shellcode       0.01      0.10      0.02       378\n",
      "         Worms       0.00      0.00      0.00        44\n",
      "\n",
      "      accuracy                           0.53     82332\n",
      "     macro avg       0.25      0.18      0.16     82332\n",
      "  weighted avg       0.64      0.53      0.47     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent, CarliniL2Method\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "critical_features = [40, 174, 159, 31, 25]\n",
    "mask = np.zeros(X_train_resampled.shape[1], dtype=np.float32)\n",
    "mask[critical_features] = 1.0\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    nb_classes=len(label_encoder.classes_),\n",
    "    input_shape=(X_train_resampled.shape[1],),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n",
    "print(\"\\n--- FGSM Attack ---\")\n",
    "fgsm = FastGradientMethod(estimator=classifier, eps=3.0, targeted=False)\n",
    "X_test_adv_fgsm = fgsm.generate(X_test_scaled, mask=mask)\n",
    "fgsm_preds = model.predict(X_test_adv_fgsm).argmax(axis=1)\n",
    "fgsm_accuracy = accuracy_score(y_test, fgsm_preds)\n",
    "fgsm_class_report = classification_report(y_test, fgsm_preds, target_names=label_encoder.classes_, zero_division=1)\n",
    "print(f\"FGSM Adversarial Accuracy: {fgsm_accuracy}\")\n",
    "print(f\"Classification Report on FGSM Adversarial Examples:\\n{fgsm_class_report}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c437d10-f2bb-4083-b621-1bd71f9d2a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PGD Attack ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2573/2573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step\n",
      "PGD Adversarial Accuracy: 0.543276004469708\n",
      "Classification Report on PGD Adversarial Examples:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.05      0.07      0.06       677\n",
      "      Backdoor       0.03      0.27      0.06       583\n",
      "           DoS       0.06      0.15      0.09      4089\n",
      "      Exploits       0.52      0.33      0.40     11132\n",
      "       Fuzzers       0.11      0.12      0.11      6062\n",
      "       Generic       1.00      0.13      0.23     18871\n",
      "        Normal       0.83      1.00      0.91     37000\n",
      "Reconnaissance       0.04      0.04      0.04      3496\n",
      "     Shellcode       0.01      0.10      0.02       378\n",
      "         Worms       0.02      0.16      0.03        44\n",
      "\n",
      "      accuracy                           0.54     82332\n",
      "     macro avg       0.27      0.24      0.20     82332\n",
      "  weighted avg       0.69      0.54      0.53     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- PGD Attack ---\")\n",
    "pgd = ProjectedGradientDescent(estimator=classifier, eps=2.0, eps_step=0.1, max_iter=100, targeted=False)\n",
    "X_test_adv_pgd = pgd.generate(X_test_scaled, mask=mask)\n",
    "pgd_preds = model.predict(X_test_adv_pgd).argmax(axis=1)\n",
    "pgd_accuracy = accuracy_score(y_test, pgd_preds)\n",
    "pgd_class_report = classification_report(y_test, pgd_preds, target_names=label_encoder.classes_, zero_division=1)\n",
    "print(f\"PGD Adversarial Accuracy: {pgd_accuracy}\")\n",
    "print(f\"Classification Report on PGD Adversarial Examples:\\n{pgd_class_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5bfbe6-53aa-43dd-b38f-5c8015d8e89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Carlini & Wagner Attack (on a subset) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93eaaf452eed4233976396e6290d5c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step\n",
      "Carlini & Wagner Adversarial Accuracy (Subset): 0.285\n",
      "\n",
      "Classification Report on Carlini & Wagner Adversarial Examples (Subset):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       1.00      0.00      0.00        20\n",
      "      Backdoor       0.27      0.60      0.37        20\n",
      "           DoS       0.67      0.10      0.17        20\n",
      "      Exploits       0.19      0.35      0.25        20\n",
      "       Fuzzers       0.23      0.40      0.29        20\n",
      "       Generic       1.00      0.30      0.46        20\n",
      "        Normal       0.29      1.00      0.45        20\n",
      "Reconnaissance       0.00      0.00      0.00        20\n",
      "     Shellcode       1.00      0.00      0.00        20\n",
      "         Worms       1.00      0.10      0.18        20\n",
      "\n",
      "      accuracy                           0.28       200\n",
      "     macro avg       0.56      0.29      0.22       200\n",
      "  weighted avg       0.56      0.28      0.22       200\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clean_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCarlini & Wagner Adversarial Accuracy (Subset): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcw_accuracy_subset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report on Carlini & Wagner Adversarial Examples (Subset):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcw_class_report_subset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: clean_accuracy,\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport\u001b[39m\u001b[38;5;124m\"\u001b[39m: clean_class_report\n\u001b[1;32m     35\u001b[0m     },\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfgsm\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: fgsm_accuracy,\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport\u001b[39m\u001b[38;5;124m\"\u001b[39m: fgsm_class_report\n\u001b[1;32m     39\u001b[0m     },\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpgd\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: pgd_accuracy,\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport\u001b[39m\u001b[38;5;124m\"\u001b[39m: pgd_class_report\n\u001b[1;32m     43\u001b[0m }\n\u001b[1;32m     44\u001b[0m }\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Save results for C&W attack on the subset\u001b[39;00m\n\u001b[1;32m     46\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcw_subset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: cw_accuracy_subset,\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport\u001b[39m\u001b[38;5;124m\"\u001b[39m: cw_class_report_subset\n\u001b[1;32m     49\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Carlini & Wagner Attack (on a subset) ---\")\n",
    "subset_indices = []\n",
    "classes_to_include = np.unique(y_test)\n",
    "for cls in classes_to_include:\n",
    "    indices = np.where(y_test == cls)[0][:20]  \n",
    "    subset_indices.extend(indices)\n",
    "\n",
    "subset_indices = np.array(subset_indices)\n",
    "X_test_subset = X_test_scaled[subset_indices]\n",
    "y_test_subset = y_test[subset_indices]\n",
    "cw = CarliniL2Method(classifier=classifier, confidence=1.0, targeted=False, max_iter=100)\n",
    "X_test_adv_cw_subset = cw.generate(X_test_subset, mask=mask)\n",
    "cw_preds_subset = model.predict(X_test_adv_cw_subset).argmax(axis=1)\n",
    "cw_accuracy_subset = accuracy_score(y_test_subset, cw_preds_subset)\n",
    "cw_class_report_subset = classification_report(\n",
    "    y_test_subset, \n",
    "    cw_preds_subset, \n",
    "    target_names=label_encoder.classes_, \n",
    "    zero_division=1\n",
    ")\n",
    "\n",
    "print(f\"Carlini & Wagner Adversarial Accuracy (Subset): {cw_accuracy_subset}\")\n",
    "print(f\"\\nClassification Report on Carlini & Wagner Adversarial Examples (Subset):\\n{cw_class_report_subset}\")\n",
    "results = {\n",
    "    \"clean\": {\n",
    "        \"accuracy\": clean_accuracy,\n",
    "        \"report\": clean_class_report\n",
    "    },\n",
    "    \"fgsm\": {\n",
    "        \"accuracy\": fgsm_accuracy,\n",
    "        \"report\": fgsm_class_report\n",
    "    },\n",
    "    \"pgd\": {\n",
    "        \"accuracy\": pgd_accuracy,\n",
    "        \"report\": pgd_class_report\n",
    "}\n",
    "}\n",
    "results[\"cw_subset\"] = {\n",
    "    \"accuracy\": cw_accuracy_subset,\n",
    "    \"report\": cw_class_report_subset\n",
    "}\n",
    "\n",
    "np.save(\"dynamic_feature_mask.npy\", mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47226656-5438-4b8c-a736-015834e19f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469us/step - accuracy: 0.6416 - loss: 0.9254 - val_accuracy: 0.8374 - val_loss: 0.4727\n",
      "Epoch 2/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 461us/step - accuracy: 0.7164 - loss: 0.7025 - val_accuracy: 0.8351 - val_loss: 0.4942\n",
      "Epoch 3/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 456us/step - accuracy: 0.7265 - loss: 0.6741 - val_accuracy: 0.8360 - val_loss: 0.4865\n",
      "Epoch 4/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 454us/step - accuracy: 0.7317 - loss: 0.6607 - val_accuracy: 0.8332 - val_loss: 0.5217\n",
      "Epoch 5/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 462us/step - accuracy: 0.7366 - loss: 0.6476 - val_accuracy: 0.8326 - val_loss: 0.5561\n",
      "Epoch 6/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 457us/step - accuracy: 0.7407 - loss: 0.6399 - val_accuracy: 0.7717 - val_loss: 0.7752\n",
      "Epoch 7/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 458us/step - accuracy: 0.7454 - loss: 0.6323 - val_accuracy: 0.8428 - val_loss: 0.8465\n",
      "Epoch 8/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 460us/step - accuracy: 0.7470 - loss: 0.6295 - val_accuracy: 0.8234 - val_loss: 0.8809\n",
      "Epoch 9/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 462us/step - accuracy: 0.7503 - loss: 0.6205 - val_accuracy: 0.8312 - val_loss: 0.9637\n",
      "Epoch 10/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 462us/step - accuracy: 0.7535 - loss: 0.6114 - val_accuracy: 0.7922 - val_loss: 1.0326\n",
      "Epoch 11/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 466us/step - accuracy: 0.7547 - loss: 0.6080 - val_accuracy: 0.7722 - val_loss: 0.7699\n",
      "Epoch 12/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 465us/step - accuracy: 0.7564 - loss: 0.6065 - val_accuracy: 0.8378 - val_loss: 0.5519\n",
      "Epoch 13/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 466us/step - accuracy: 0.7562 - loss: 0.6066 - val_accuracy: 0.8346 - val_loss: 0.6656\n",
      "Epoch 14/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 466us/step - accuracy: 0.7579 - loss: 0.6007 - val_accuracy: 0.8314 - val_loss: 1.0000\n",
      "Epoch 15/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 468us/step - accuracy: 0.7592 - loss: 0.5971 - val_accuracy: 0.8394 - val_loss: 0.9858\n",
      "Epoch 16/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 466us/step - accuracy: 0.7586 - loss: 0.5985 - val_accuracy: 0.8334 - val_loss: 1.1432\n",
      "Epoch 17/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 475us/step - accuracy: 0.7610 - loss: 0.5934 - val_accuracy: 0.8374 - val_loss: 1.1713\n",
      "Epoch 18/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 493us/step - accuracy: 0.7628 - loss: 0.5887 - val_accuracy: 0.8387 - val_loss: 1.2449\n",
      "Epoch 19/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 487us/step - accuracy: 0.7609 - loss: 0.5931 - val_accuracy: 0.8122 - val_loss: 0.7161\n",
      "Epoch 20/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 474us/step - accuracy: 0.7622 - loss: 0.5920 - val_accuracy: 0.8377 - val_loss: 1.4227\n",
      "Epoch 21/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 460us/step - accuracy: 0.7631 - loss: 0.5883 - val_accuracy: 0.8308 - val_loss: 1.9879\n",
      "Epoch 22/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 497us/step - accuracy: 0.7617 - loss: 0.5884 - val_accuracy: 0.8277 - val_loss: 0.9968\n",
      "Epoch 23/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479us/step - accuracy: 0.7624 - loss: 0.5896 - val_accuracy: 0.7650 - val_loss: 0.9703\n",
      "Epoch 24/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 481us/step - accuracy: 0.7633 - loss: 0.5891 - val_accuracy: 0.8338 - val_loss: 1.7655\n",
      "Epoch 25/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 504us/step - accuracy: 0.7632 - loss: 0.5868 - val_accuracy: 0.8406 - val_loss: 1.2582\n",
      "Epoch 26/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502us/step - accuracy: 0.7665 - loss: 0.5789 - val_accuracy: 0.8371 - val_loss: 2.5932\n",
      "Epoch 27/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 489us/step - accuracy: 0.7655 - loss: 0.5797 - val_accuracy: 0.8394 - val_loss: 2.0439\n",
      "Epoch 28/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - accuracy: 0.7652 - loss: 0.5794 - val_accuracy: 0.8412 - val_loss: 1.3098\n",
      "Epoch 29/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 503us/step - accuracy: 0.7653 - loss: 0.5806 - val_accuracy: 0.8352 - val_loss: 2.2177\n",
      "Epoch 30/30\n",
      "\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 498us/step - accuracy: 0.7672 - loss: 0.5755 - val_accuracy: 0.8217 - val_loss: 6.0637\n",
      "\u001b[1m2573/2573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277us/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   88   475    41    73     0     0     0     0     0     0]\n",
      " [   88   400    45    34     6     0     0     0     9     1]\n",
      " [  117  2604   345   728    95     6     4    63    94    33]\n",
      " [  278  2796   476  6118   447     3     8   359   320   327]\n",
      " [  177   969   123   224  3774     0    93    27   667     8]\n",
      " [    4    53   163  1310   482 16751     0    10    70    28]\n",
      " [    0     0     0     0     0     0 37000     0     0     0]\n",
      " [    1   342    30   103    45     0     7  2844   108    16]\n",
      " [    0    11     3    16    25     0     0    25   297     1]\n",
      " [    0     0     1     4     2     0     0     1     3    33]]\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.12      0.13      0.12       677\n",
      "      Backdoor       0.05      0.69      0.10       583\n",
      "           DoS       0.28      0.08      0.13      4089\n",
      "      Exploits       0.71      0.55      0.62     11132\n",
      "       Fuzzers       0.77      0.62      0.69      6062\n",
      "       Generic       1.00      0.89      0.94     18871\n",
      "        Normal       1.00      1.00      1.00     37000\n",
      "Reconnaissance       0.85      0.81      0.83      3496\n",
      "     Shellcode       0.19      0.79      0.31       378\n",
      "         Worms       0.07      0.75      0.13        44\n",
      "\n",
      "      accuracy                           0.82     82332\n",
      "     macro avg       0.50      0.63      0.49     82332\n",
      "  weighted avg       0.88      0.82      0.84     82332\n",
      "\n",
      "\n",
      "--- FGSM Attack ---\n",
      "\u001b[1m2573/2573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278us/step\n",
      "FGSM Adversarial Accuracy: 0.7378783462080357\n",
      "\n",
      "Classification Report on FGSM Adversarial Examples:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.05      0.10      0.07       677\n",
      "      Backdoor       0.03      0.35      0.06       583\n",
      "           DoS       0.10      0.14      0.12      4089\n",
      "      Exploits       0.48      0.27      0.35     11132\n",
      "       Fuzzers       0.54      0.32      0.40      6062\n",
      "       Generic       0.99      0.89      0.94     18871\n",
      "        Normal       0.96      1.00      0.98     37000\n",
      "Reconnaissance       0.50      0.31      0.38      3496\n",
      "     Shellcode       0.07      0.13      0.09       378\n",
      "         Worms       0.01      0.11      0.01        44\n",
      "\n",
      "      accuracy                           0.74     82332\n",
      "     macro avg       0.37      0.36      0.34     82332\n",
      "  weighted avg       0.79      0.74      0.75     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, QuantileTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = train_data.drop(columns=['attack_cat'])\n",
    "y_train = train_data['attack_cat']\n",
    "X_test = test_data.drop(columns=['attack_cat'])\n",
    "y_test = test_data['attack_cat']\n",
    "categorical_features = ['proto', 'service', 'state']\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_encoded)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "X_train_scaled = quantile_transformer.fit_transform(X_train_scaled)\n",
    "X_test_scaled = quantile_transformer.transform(X_test_scaled)\n",
    "num_classes = len(np.unique(y_train_encoded))\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = mlp_model.fit(X_train_scaled, y_train_resampled, epochs=30, batch_size=32, validation_data=(X_test_scaled, y_test_encoded))\n",
    "y_pred_encoded = mlp_model.predict(X_test_scaled).argmax(axis=1)\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test_encoded)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_decoded, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_decoded, y_pred))\n",
    "critical_features = [40, 174, 159, 31, 25] \n",
    "mask = np.zeros(X_train_scaled.shape[1], dtype=np.float32)\n",
    "mask[critical_features] = 1.0\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=mlp_model,\n",
    "    nb_classes=num_classes,\n",
    "    input_shape=(X_train_scaled.shape[1],),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n",
    "\n",
    "print(\"\\n--- FGSM Attack ---\")\n",
    "fgsm = FastGradientMethod(estimator=classifier, eps=3.0, targeted=False)\n",
    "X_test_adv_fgsm = fgsm.generate(X_test_scaled, mask=mask)\n",
    "fgsm_preds = mlp_model.predict(X_test_adv_fgsm).argmax(axis=1)\n",
    "fgsm_accuracy = accuracy_score(y_test_encoded, fgsm_preds)\n",
    "fgsm_class_report = classification_report(y_test_encoded, fgsm_preds, target_names=label_encoder.classes_, zero_division=1)\n",
    "print(f\"FGSM Adversarial Accuracy: {fgsm_accuracy}\")\n",
    "print(f\"\\nClassification Report on FGSM Adversarial Examples:\\n{fgsm_class_report}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c15238-8a20-4935-9a7a-a54e4c3949b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e7f9a5-d700-4d50-af60-74231df8580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PGD Attack ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 20:50:24.212260: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2573/2573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step\n",
      "PGD Adversarial Accuracy: 0.6777923529125978\n",
      "\n",
      "Classification Report on PGD Adversarial Examples:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.06      0.26      0.10       677\n",
      "      Backdoor       0.02      0.18      0.04       583\n",
      "           DoS       0.10      0.18      0.13      4089\n",
      "      Exploits       0.44      0.17      0.25     11132\n",
      "       Fuzzers       0.36      0.23      0.28      6062\n",
      "       Generic       0.98      0.73      0.83     18871\n",
      "        Normal       0.92      1.00      0.96     37000\n",
      "Reconnaissance       0.41      0.18      0.25      3496\n",
      "     Shellcode       0.05      0.24      0.08       378\n",
      "         Worms       0.01      0.16      0.01        44\n",
      "\n",
      "      accuracy                           0.68     82332\n",
      "     macro avg       0.34      0.33      0.29     82332\n",
      "  weighted avg       0.75      0.68      0.69     82332\n",
      "\n",
      "\n",
      "--- Carlini & Wagner Attack (on a subset) ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- PGD Attack ---\")\n",
    "pgd = ProjectedGradientDescent(estimator=classifier, eps=3.0, eps_step=0.1, max_iter=100, targeted=False)\n",
    "X_test_adv_pgd = pgd.generate(X_test_scaled, mask=mask)\n",
    "pgd_preds = mlp_model.predict(X_test_adv_pgd).argmax(axis=1)\n",
    "pgd_accuracy = accuracy_score(y_test_encoded, pgd_preds)\n",
    "pgd_class_report = classification_report(y_test_encoded, pgd_preds, target_names=label_encoder.classes_, zero_division=1)\n",
    "print(f\"PGD Adversarial Accuracy: {pgd_accuracy}\")\n",
    "print(f\"\\nClassification Report on PGD Adversarial Examples:\\n{pgd_class_report}\")\n",
    "print(\"\\n--- Carlini & Wagner Attack (on a subset) ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa74143-85ea-4e4a-9d88-58f1ab389a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b3b9c764274158975340f80ad74b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n",
      "Carlini & Wagner Adversarial Accuracy (Subset): 0.51\n",
      "\n",
      "Classification Report on Carlini & Wagner Adversarial Examples (Subset):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.00      0.00      0.00        20\n",
      "      Backdoor       0.25      0.85      0.38        20\n",
      "           DoS       0.25      0.05      0.08        20\n",
      "      Exploits       0.36      0.45      0.40        20\n",
      "       Fuzzers       0.59      0.50      0.54        20\n",
      "       Generic       1.00      0.75      0.86        20\n",
      "        Normal       0.65      1.00      0.78        20\n",
      "Reconnaissance       0.65      0.55      0.59        20\n",
      "     Shellcode       1.00      0.25      0.40        20\n",
      "         Worms       0.93      0.70      0.80        20\n",
      "\n",
      "      accuracy                           0.51       200\n",
      "     macro avg       0.57      0.51      0.48       200\n",
      "  weighted avg       0.57      0.51      0.48       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "subset_indices = []\n",
    "classes_to_include = np.unique(y_test_encoded)\n",
    "for cls in classes_to_include:\n",
    "    indices = np.where(y_test_encoded == cls)[0][:20]  \n",
    "    subset_indices.extend(indices)\n",
    "subset_indices = np.array(subset_indices)\n",
    "X_test_subset = X_test_scaled[subset_indices]\n",
    "y_test_subset = y_test_encoded[subset_indices]\n",
    "cw = CarliniL2Method(classifier=classifier, confidence=1.0, targeted=False, max_iter=100)\n",
    "X_test_adv_cw_subset = cw.generate(X_test_subset, mask=mask)\n",
    "cw_preds_subset = mlp_model.predict(X_test_adv_cw_subset).argmax(axis=1)\n",
    "cw_accuracy_subset = accuracy_score(y_test_subset, cw_preds_subset)\n",
    "cw_class_report_subset = classification_report(\n",
    "    y_test_subset, \n",
    "    cw_preds_subset, \n",
    "    target_names=label_encoder.classes_, \n",
    "    zero_division=1\n",
    ")\n",
    "\n",
    "print(f\"Carlini & Wagner Adversarial Accuracy (Subset): {cw_accuracy_subset}\")\n",
    "print(f\"\\nClassification Report on Carlini & Wagner Adversarial Examples (Subset):\\n{cw_class_report_subset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7bfb5d-be30-461f-aa4b-30016e3cb840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
