{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8755de7a-b253-4127-9932-e7b845826058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e2bd96e-60fe-4369-bda8-ce54811136c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing sets from separate files\n",
    "train_data = pd.read_csv(\"/Users/marlenawasiak/Desktop/Data_Collection/UNSW_NB15_training-set.csv\")\n",
    "test_data = pd.read_csv(\"/Users/marlenawasiak/Desktop/Data_Collection/UNSW_NB15_testing-set.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec5da22a-e577-4319-824e-e4e59c9d5673",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['attack_cat'])\n",
    "y_train = train_data['attack_cat']\n",
    "\n",
    "X_test = test_data.drop(columns=['attack_cat'])\n",
    "y_test = test_data['attack_cat']\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['proto', 'service', 'state']\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Align test set columns with training set columns (fill missing columns with 0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Encode the target label (attack category) in both training and test sets\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a344669-e3f1-48f6-be15-89f9c37a6f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the training and test sets\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)  # Fit and transform on training set\n",
    "X_test_scaled = scaler.transform(X_test)                     # Only transform the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f292b48b-22c8-45a2-9a8f-5a3909e1cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[    0   584    20    40    18    14     1     0     0     0]\n",
      " [    0   490    20     6     9    14    22     2    17     3]\n",
      " [   19  2740    38   454    87    14   360    55   205   117]\n",
      " [  116  2930    62  4808   506    28   990    70   565  1057]\n",
      " [    0  1180    42    17  3365    28   416   138   761   115]\n",
      " [    5    36     0   290    91 18142   104     5   154    44]\n",
      " [ 1809     0     0    43  6639     0 27816   200   395    98]\n",
      " [    1   308     2     2    43     0   124  2468   158   390]\n",
      " [    0     0     0     0     5     0    25    16   332     0]\n",
      " [    0     0     0     0     2     0     0     0     8    34]]\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.00      0.00      0.00       677\n",
      "      Backdoor       0.06      0.84      0.11       583\n",
      "           DoS       0.21      0.01      0.02      4089\n",
      "      Exploits       0.85      0.43      0.57     11132\n",
      "       Fuzzers       0.31      0.56      0.40      6062\n",
      "       Generic       0.99      0.96      0.98     18871\n",
      "        Normal       0.93      0.75      0.83     37000\n",
      "Reconnaissance       0.84      0.71      0.77      3496\n",
      "     Shellcode       0.13      0.88      0.22       378\n",
      "         Worms       0.02      0.77      0.04        44\n",
      "\n",
      "      accuracy                           0.70     82332\n",
      "     macro avg       0.43      0.59      0.39     82332\n",
      "  weighted avg       0.83      0.70      0.74     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Random Forest model with class weight adjustments\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',  # Helps handle any remaining class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the resampled and scaled training set\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate on the scaled test set\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Decode the target labels back to their original categories for interpretation\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_decoded, y_pred_decoded))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b475d87d-6a2a-4472-a860-e0d955586649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix After Extreme Targeted Attack (Random Forest):\n",
      "[[    1     3     5    69   109     2   482     0     0     6]\n",
      " [    2     1     2    51   115     5   400     0     4     3]\n",
      " [   10    13    27   321   368    15  3293     5     7    30]\n",
      " [   40    16    41  1166   919    15  8729     8    14   184]\n",
      " [   17    10    30   598   973    10  4301     8    19    96]\n",
      " [    9     6    87   653  3418  2216 12433     7    12    30]\n",
      " [   19     9    34   674   748    10 35356    11    12   127]\n",
      " [    8    11    28   299   408     3  2650     2    23    64]\n",
      " [    2     0     2    31    47     0   290     1     3     2]\n",
      " [    0     0     0     8     4     0    29     0     1     2]]\n",
      "\n",
      "Classification Report After Extreme Targeted Attack (Random Forest):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.01      0.00      0.00       677\n",
      "      Backdoor       0.01      0.00      0.00       583\n",
      "           DoS       0.11      0.01      0.01      4089\n",
      "      Exploits       0.30      0.10      0.16     11132\n",
      "       Fuzzers       0.14      0.16      0.15      6062\n",
      "       Generic       0.97      0.12      0.21     18871\n",
      "        Normal       0.52      0.96      0.67     37000\n",
      "Reconnaissance       0.05      0.00      0.00      3496\n",
      "     Shellcode       0.03      0.01      0.01       378\n",
      "         Worms       0.00      0.05      0.01        44\n",
      "\n",
      "      accuracy                           0.48     82332\n",
      "     macro avg       0.21      0.14      0.12     82332\n",
      "  weighted avg       0.52      0.48      0.38     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extreme_targeted_attack_v3(X, critical_feature_indices, epsilon_critical=2.5, epsilon_noise=0.3, iterations=10):\n",
    "    \"\"\"\n",
    "    Applies an even stronger targeted perturbation.\n",
    "    Args:\n",
    "    - X: Test dataset (scaled).\n",
    "    - critical_feature_indices: Indices of critical features to perturb.\n",
    "    - epsilon_critical: Magnitude of perturbation for critical features.\n",
    "    - epsilon_noise: Magnitude of noise for non-critical features.\n",
    "    - iterations: Number of iterative perturbations to apply.\n",
    "    Returns:\n",
    "    - X_perturbed: Perturbed dataset.\n",
    "    \"\"\"\n",
    "    X_perturbed = X.copy()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Perturb critical features with stronger perturbation\n",
    "        for feature_idx in critical_feature_indices:\n",
    "            perturbation = np.random.uniform(-epsilon_critical, epsilon_critical, size=X_perturbed.shape[0])\n",
    "            X_perturbed[:, feature_idx] += perturbation\n",
    "        \n",
    "        # Add noise to all features\n",
    "        for feature_idx in range(X.shape[1]):\n",
    "            perturbation = np.random.normal(0, epsilon_noise, size=X_perturbed.shape[0])\n",
    "            X_perturbed[:, feature_idx] += perturbation\n",
    "    \n",
    "    return X_perturbed\n",
    "\n",
    "# Step 1: Apply the Extreme Targeted Attack\n",
    "X_test_perturbed_extreme = extreme_targeted_attack_v3(X_test_scaled, critical_feature_indices, epsilon_critical=2.7, epsilon_noise=0.5, iterations=10)\n",
    "\n",
    "# Step 2: Evaluate the Model on Extremely Perturbed Data\n",
    "y_pred_perturbed_extreme = rf_model.predict(X_test_perturbed_extreme)\n",
    "\n",
    "# Decode predictions back to original categories\n",
    "y_pred_perturbed_extreme_decoded = label_encoder.inverse_transform(y_pred_perturbed_extreme)\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Step 3: Evaluate Perturbed Predictions\n",
    "print(\"Confusion Matrix After Extreme Targeted Attack (Random Forest):\")\n",
    "print(confusion_matrix(y_test_decoded, y_pred_perturbed_extreme_decoded))\n",
    "\n",
    "print(\"\\nClassification Report After Extreme Targeted Attack (Random Forest):\")\n",
    "print(classification_report(y_test_decoded, y_pred_perturbed_extreme_decoded))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5d0da6-82b3-4057-8ebe-baaeaf855ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/art/estimators/certification/__init__.py:30: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.attacks.evasion import BoundaryAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a99a470-8216-40cc-ac68-c6a6216553a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:40:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7403439731817519\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.07      0.19      0.10       677\n",
      "      Backdoor       0.02      0.24      0.03       583\n",
      "           DoS       0.11      0.09      0.10      4089\n",
      "      Exploits       0.77      0.41      0.54     11132\n",
      "       Fuzzers       0.41      0.70      0.52      6062\n",
      "       Generic       1.00      0.60      0.75     18871\n",
      "        Normal       1.00      1.00      1.00     37000\n",
      "Reconnaissance       0.91      0.78      0.84      3496\n",
      "     Shellcode       0.27      0.97      0.43       378\n",
      "         Worms       0.44      0.80      0.56        44\n",
      "\n",
      "      accuracy                           0.74     82332\n",
      "     macro avg       0.50      0.58      0.49     82332\n",
      "  weighted avg       0.86      0.74      0.78     82332\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  126   196   206   148     1     0     0     0     0     0]\n",
      " [  126   139   205   103     4     0     0     0     6     0]\n",
      " [  475  2465   378   419   217     0     0    33    96     6]\n",
      " [  702  4099   506  4598   726     0     0   157   314    30]\n",
      " [  288   387   425   313  4263     0     0     7   379     0]\n",
      " [   12   178  1833   315  5081 11303     0    58    82     9]\n",
      " [    0     0     0     0     0     0 37000     0     0     0]\n",
      " [   39   543     8    37    26     0     0  2744    99     0]\n",
      " [    0     3     0     2     4     0     0     1   368     0]\n",
      " [    0     2     0     6     1     0     0     0     0    35]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load your dataset\n",
    "# Assume 'train_data' and 'test_data' are already loaded DataFrames with the UNSW dataset\n",
    "\n",
    "# Prepare training and test sets\n",
    "X_train = train_data.drop(columns=['attack_cat'])\n",
    "y_train = train_data['attack_cat']\n",
    "X_test = test_data.drop(columns=['attack_cat'])\n",
    "y_test = test_data['attack_cat']\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['proto', 'service', 'state']\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Align test set columns with training set columns\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Encode the target label\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Handle class imbalance with RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)  # Fit and transform on training set\n",
    "X_test_scaled = scaler.transform(X_test)                     # Only transform the test set\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "91201c9f-16bc-4659-9056-c3487df73688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix After Stronger Attack (XGBoost):\n",
      "[[    0   207   323   117    30     0     0     0     0     0]\n",
      " [    4   125   299   117    34     0     0     2     1     1]\n",
      " [   24  2799   559   385   226     0     0     7     6    83]\n",
      " [   92  5086  1569  2838   982     0     0    22    14   529]\n",
      " [    8  1022  1274  1095  2588     0     0    19    42    14]\n",
      " [    2  2535  3490   898  5374  6536     0     9     3    24]\n",
      " [    0     0     0     0     0     0 37000     0     0     0]\n",
      " [    1   875   623   596   527     0     0   654   128    92]\n",
      " [    0    83    96    79    81     0     0     1    38     0]\n",
      " [    0    11     6     9     5     0     0     0     1    12]]\n",
      "\n",
      "Classification Report After Stronger Targeted Attack (XGBoost):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.00      0.00      0.00       677\n",
      "      Backdoor       0.01      0.21      0.02       583\n",
      "           DoS       0.07      0.14      0.09      4089\n",
      "      Exploits       0.46      0.25      0.33     11132\n",
      "       Fuzzers       0.26      0.43      0.33      6062\n",
      "       Generic       1.00      0.35      0.51     18871\n",
      "        Normal       1.00      1.00      1.00     37000\n",
      "Reconnaissance       0.92      0.19      0.31      3496\n",
      "     Shellcode       0.16      0.10      0.12       378\n",
      "         Worms       0.02      0.27      0.03        44\n",
      "\n",
      "      accuracy                           0.61     82332\n",
      "     macro avg       0.39      0.29      0.27     82332\n",
      "  weighted avg       0.80      0.61      0.65     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def dynamic_targeted_attack(X, critical_feature_indices, initial_epsilon=0.1, max_iterations=20):\n",
    "    \"\"\"\n",
    "    Perform a progressively stronger targeted attack with dynamic epsilon.\n",
    "    \n",
    "    Args:\n",
    "    - X: Input feature matrix.\n",
    "    - critical_feature_indices: Indices of the features to be perturbed.\n",
    "    - initial_epsilon: Initial perturbation magnitude.\n",
    "    - max_iterations: Number of iterations for iterative perturbation.\n",
    "    \n",
    "    Returns:\n",
    "    - X_perturbed: Perturbed feature matrix.\n",
    "    \"\"\"\n",
    "    X_perturbed = X.copy()\n",
    "    epsilon = initial_epsilon\n",
    "\n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        # Increase epsilon dynamically for each iteration\n",
    "        epsilon_step = epsilon * (iteration / max_iterations)\n",
    "        \n",
    "        for feature_idx in critical_feature_indices:\n",
    "            # Perturb features with dynamic epsilon\n",
    "            perturbation = np.random.choice([-epsilon_step, epsilon_step], size=X_perturbed.shape[0])\n",
    "            X_perturbed[:, feature_idx] += perturbation * np.random.uniform(1, 2, size=X_perturbed.shape[0])\n",
    "        \n",
    "        # Optionally clip features to remain within valid bounds\n",
    "        X_perturbed = np.clip(X_perturbed, X.min(axis=0), X.max(axis=0))\n",
    "    \n",
    "    return X_perturbed\n",
    "\n",
    "\n",
    "# Define critical features based on SHAP and interaction values\n",
    "critical_features = [6, 9, 7, 8, 5, 4]  # Example indices for critical features (adjust based on SHAP)\n",
    "initial_epsilon = 4.0  # Starting perturbation magnitude\n",
    "max_iterations = 20  # Increase iterations for greater impact\n",
    "\n",
    "# Apply the dynamic targeted attack\n",
    "X_test_perturbed = dynamic_targeted_attack(X_test_scaled, critical_features, initial_epsilon=initial_epsilon, max_iterations=max_iterations)\n",
    "\n",
    "# Re-evaluate the model on the perturbed data\n",
    "y_pred_perturbed = xgb_model.predict(X_test_perturbed)\n",
    "\n",
    "# Confusion matrix and classification report for the perturbed data\n",
    "conf_matrix_perturbed = confusion_matrix(y_test, y_pred_perturbed)\n",
    "classification_report_perturbed = classification_report(y_test, y_pred_perturbed, target_names=label_encoder.classes_)\n",
    "\n",
    "# Display the results\n",
    "print(\"Confusion Matrix After Stronger Attack (XGBoost):\")\n",
    "print(conf_matrix_perturbed)\n",
    "print(\"\\nClassification Report After Stronger Targeted Attack (XGBoost):\")\n",
    "print(classification_report_perturbed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f1fae-0a50-418d-ae9e-951b7ca97481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
